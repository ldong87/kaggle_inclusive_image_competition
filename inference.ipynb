{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6e4c794d707761744877453d</td>\n",
       "      <td>/m/01g317 /m/05s2s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44683973366a3546784d773d</td>\n",
       "      <td>/m/01g317 /m/05s2s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45526a6d51764c4e4633383d</td>\n",
       "      <td>/m/01g317 /m/05s2s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66563932463636774a786b3d</td>\n",
       "      <td>/m/01g317 /m/05s2s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4845534e6a546a76704f383d</td>\n",
       "      <td>/m/01g317 /m/05s2s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   image_id              labels\n",
       "0  6e4c794d707761744877453d  /m/01g317 /m/05s2s\n",
       "1  44683973366a3546784d773d  /m/01g317 /m/05s2s\n",
       "2  45526a6d51764c4e4633383d  /m/01g317 /m/05s2s\n",
       "3  66563932463636774a786b3d  /m/01g317 /m/05s2s\n",
       "4  4845534e6a546a76704f383d  /m/01g317 /m/05s2s"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "files = glob.glob('input/stage_2_images/*.jpg')\n",
    "imageid = list(map(lambda x: x.split('/')[-1][:-4], files))\n",
    "sub2 = pd.DataFrame({'image_id':imageid, 'labels':' '.join(['/m/01g317', '/m/05s2s'])})\n",
    "sub2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2.to_csv('input/stage_2_sample_submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resource\n",
    "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (4096, rlimit[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed = 34\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed) \n",
    "torch.cuda.manual_seed_all(seed) \n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helpers import Imagefolder_inference as myImagefolder_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(load_path, model, optimizer=None, warmup=False):\n",
    "    if os.path.isfile(load_path):\n",
    "        print(\"-> Loading checkpoint '{}'\".format(load_path))\n",
    "        checkpoint = torch.load(load_path)\n",
    "        epoch = checkpoint['epoch'] if not warmup else -1\n",
    "        acc_valid = checkpoint['acc_valid']\n",
    "        acc_train = checkpoint['acc_train']\n",
    "        loss_valid = checkpoint['loss_valid']\n",
    "        loss_train = checkpoint['loss_train']\n",
    "        state_dict = checkpoint['state_dict']\n",
    "        itrn_chkpt = checkpoint['step'] if not warmup else 0\n",
    "        \n",
    "        model.load_state_dict(state_dict)\n",
    "#         from collections import OrderedDict\n",
    "#         new_state_dict = OrderedDict()\n",
    "#         for k, v in state_dict.items():\n",
    "#             name = k[7:] # remove 'module.' of dataparallel\n",
    "#             new_state_dict[name]=v\n",
    "#         model.load_state_dict(new_state_dict)\n",
    "            \n",
    "        print(\"-> Loaded checkpoint at epoch {} step {} \".format(epoch, itrn_chkpt))\n",
    "        if warmup:\n",
    "            return epoch, acc_valid, acc_train, loss_train, loss_valid, itrn_chkpt\n",
    "        else:\n",
    "            if optimizer != None:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "                for state in optimizer.state.values():\n",
    "                    for k, v in state.items():\n",
    "                        if torch.is_tensor(v):\n",
    "                            state[k] = v.cuda()\n",
    "            return epoch-1, acc_valid, acc_train, loss_train, loss_valid, itrn_chkpt\n",
    "    else:\n",
    "        print(\"-> No checkpoint found at '{}'\".format(load_path))\n",
    "        return None\n",
    "\n",
    "def labels_loop(list_class, label):\n",
    "    for ilabel in label:\n",
    "        for j in ilabel:\n",
    "            list_class[j] += 1\n",
    "    return list_class\n",
    "    \n",
    "class SoftF2Loss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SoftF2Loss,self).__init__()\n",
    "        \n",
    "    def forward(self, logits, labels):\n",
    "        __small_value=1e-6\n",
    "        beta = 2\n",
    "        batch_size = logits.size()[0]\n",
    "        p = torch.nn.functional.sigmoid(logits)\n",
    "        l = labels\n",
    "        num_pos = torch.sum(p, 1) + __small_value\n",
    "        num_pos_hat = torch.sum(l, 1) + __small_value\n",
    "        tp = torch.sum(l * p, 1)\n",
    "        precise = tp / num_pos\n",
    "        recall = tp / num_pos_hat\n",
    "        fs = (1 + beta * beta) * precise * recall / (beta * beta * precise + recall + __small_value)\n",
    "        loss = fs.sum() / batch_size\n",
    "        return (1 - loss)\n",
    "    \n",
    "def add_to_result(result, valid, img, path, pred, labels_val):\n",
    "    batch_size = pred.shape[0]\n",
    "    for ii in range(batch_size):\n",
    "        # result is dict, keys are classes, values are probs, pred is probs\n",
    "        img.append(path[ii].split('/')[-1][:-4])\n",
    "        for kk, p in enumerate(pred[ii]):\n",
    "            result[kk].append(float(p)) # result is probs\n",
    "        if labels_val is not None:\n",
    "            for kk, l in enumerate(labels_val[ii]):\n",
    "                valid[kk].append(int(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resize = (224,224)\n",
    "batch_size_valid = 64*2\n",
    "num_workers_valid = 12*2\n",
    "\n",
    "chkpt = True\n",
    "warmup = False\n",
    "chkpt_file = 'accval-0.1413_lossval-56.2363_epoch-9_step-10440_checkpoint.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform_valid = transforms.Compose([transforms.Resize(image_resize),transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgset_valid = myImagefolder_inf.DatasetFolder(root='input/stage_2_images/', label_file='input/stage_2_sample_submission2.csv', desc_file='input/label_hmn_mch_desc.csv', transform=img_transform_valid)\n",
    "loader_valid = torch.utils.data.DataLoader(imgset_valid, batch_size=batch_size_valid, num_workers=num_workers_valid, shuffle=False)\n",
    "n_class = len(imgset_valid.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from senet import se_resnext101_32x4d\n",
    "device = torch.device('cuda')\n",
    "model = se_resnext101_32x4d(pretrained=None, num_classes=553 if (chkpt&warmup) else n_class, bn0=True)\n",
    "model.avg_pool = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "criterion = SoftF2Loss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Loading checkpoint 'chkpt/accval-0.1413_lossval-56.2363_epoch-9_step-10440_checkpoint.pth'\n",
      "-> Loaded checkpoint at epoch 8 step 10440 \n",
      "7 0.14126008805833443 0.1410138576230247 tensor(119.0210, device='cuda:0', requires_grad=True) tensor(56.2363, device='cuda:0') 10440\n"
     ]
    }
   ],
   "source": [
    "if chkpt:\n",
    "    epoch, acc_valid, acc_train, loss_valid, loss_train, itrn_chkpt = load_checkpoint('chkpt/'+chkpt_file, \n",
    "                                                   model, None, warmup=warmup)\n",
    "    if warmup:\n",
    "        model.module.last_linear = nn.Linear(model.module.last_linear.in_features, n_class).to(device)\n",
    "    print(epoch, acc_valid, acc_train, loss_valid, loss_train, itrn_chkpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_Step:0\n",
      "Loader:6.296557426452637\n",
      "Inference:6.846416711807251\n",
      "Val_Step:1\n",
      "Loader:4.656213760375977\n",
      "Inference:0.2714226245880127\n",
      "Val_Step:2\n",
      "Loader:5.1169281005859375\n",
      "Inference:0.26366209983825684\n",
      "Val_Step:3\n",
      "Loader:5.0422279834747314\n",
      "Inference:0.25800108909606934\n",
      "Val_Step:4\n",
      "Loader:4.90475058555603\n",
      "Inference:0.5064373016357422\n",
      "Val_Step:5\n",
      "Loader:4.674800157546997\n",
      "Inference:0.2530026435852051\n",
      "Val_Step:6\n",
      "Loader:4.805131196975708\n",
      "Inference:0.2553749084472656\n",
      "Val_Step:7\n",
      "Loader:4.677137136459351\n",
      "Inference:0.25246524810791016\n",
      "Val_Step:8\n",
      "Loader:4.757432460784912\n",
      "Inference:0.25661802291870117\n",
      "Val_Step:9\n",
      "Loader:4.830447196960449\n",
      "Inference:0.2548055648803711\n",
      "Val_Step:10\n",
      "Loader:4.9616029262542725\n",
      "Inference:0.2722620964050293\n",
      "Val_Step:11\n",
      "Loader:4.776740074157715\n",
      "Inference:0.25931572914123535\n",
      "Val_Step:12\n",
      "Loader:4.481338262557983\n",
      "Inference:0.2522876262664795\n",
      "Val_Step:13\n",
      "Loader:4.82720160484314\n",
      "Inference:0.2558867931365967\n",
      "Val_Step:14\n",
      "Loader:4.668629169464111\n",
      "Inference:0.2531008720397949\n",
      "Val_Step:15\n",
      "Loader:4.833582401275635\n",
      "Inference:0.2544989585876465\n",
      "Val_Step:16\n",
      "Loader:4.627707004547119\n",
      "Inference:0.25198888778686523\n",
      "Val_Step:17\n",
      "Loader:4.71293044090271\n",
      "Inference:0.2539985179901123\n",
      "Val_Step:18\n",
      "Loader:4.752366065979004\n",
      "Inference:0.25248146057128906\n",
      "Val_Step:19\n",
      "Loader:4.867658853530884\n",
      "Inference:0.26636719703674316\n",
      "Val_Step:20\n",
      "Loader:4.647862672805786\n",
      "Inference:0.2722492218017578\n",
      "Val_Step:21\n",
      "Loader:4.827051162719727\n",
      "Inference:0.2574303150177002\n",
      "Val_Step:22\n",
      "Loader:4.62187647819519\n",
      "Inference:0.24754571914672852\n",
      "Val_Step:23\n",
      "Loader:4.545306205749512\n",
      "Inference:0.254925012588501\n",
      "Val_Step:24\n",
      "Loader:4.85908579826355\n",
      "Inference:1.2434542179107666\n",
      "Val_Step:25\n",
      "Loader:4.711259603500366\n",
      "Inference:0.2532780170440674\n",
      "Val_Step:26\n",
      "Loader:4.882151126861572\n",
      "Inference:0.256030797958374\n",
      "Val_Step:27\n",
      "Loader:4.7466065883636475\n",
      "Inference:0.25425291061401367\n",
      "Val_Step:28\n",
      "Loader:4.82439923286438\n",
      "Inference:0.2576777935028076\n",
      "Val_Step:29\n",
      "Loader:4.814460039138794\n",
      "Inference:0.26700353622436523\n",
      "Val_Step:30\n",
      "Loader:4.898450136184692\n",
      "Inference:0.2611873149871826\n",
      "Val_Step:31\n",
      "Loader:4.478928327560425\n",
      "Inference:0.2519571781158447\n",
      "Val_Step:32\n",
      "Loader:4.746624946594238\n",
      "Inference:0.25829195976257324\n",
      "Val_Step:33\n",
      "Loader:4.859530448913574\n",
      "Inference:0.2513124942779541\n",
      "Val_Step:34\n",
      "Loader:4.936591863632202\n",
      "Inference:0.2544896602630615\n",
      "Val_Step:35\n",
      "Loader:4.785898685455322\n",
      "Inference:0.25174927711486816\n",
      "Val_Step:36\n",
      "Loader:4.799304723739624\n",
      "Inference:0.25014233589172363\n",
      "Val_Step:37\n",
      "Loader:4.680185794830322\n",
      "Inference:0.2652311325073242\n",
      "Val_Step:38\n",
      "Loader:4.89750599861145\n",
      "Inference:0.2680809497833252\n",
      "Val_Step:39\n",
      "Loader:4.808658599853516\n",
      "Inference:0.2548089027404785\n",
      "Val_Step:40\n",
      "Loader:4.68624210357666\n",
      "Inference:0.25063371658325195\n",
      "Val_Step:41\n",
      "Loader:4.805860757827759\n",
      "Inference:0.25104331970214844\n",
      "Val_Step:42\n",
      "Loader:4.789278030395508\n",
      "Inference:0.25496625900268555\n",
      "Val_Step:43\n",
      "Loader:4.8910417556762695\n",
      "Inference:0.25089192390441895\n",
      "Val_Step:44\n",
      "Loader:4.786336898803711\n",
      "Inference:0.2545168399810791\n",
      "Val_Step:45\n",
      "Loader:4.83624529838562\n",
      "Inference:2.0896313190460205\n",
      "Val_Step:46\n",
      "Loader:4.809343576431274\n",
      "Inference:0.26419663429260254\n",
      "Val_Step:47\n",
      "Loader:4.809930801391602\n",
      "Inference:0.26073217391967773\n",
      "Val_Step:48\n",
      "Loader:4.887518882751465\n",
      "Inference:0.25341248512268066\n",
      "Val_Step:49\n",
      "Loader:4.87003755569458\n",
      "Inference:0.2507152557373047\n",
      "Val_Step:50\n",
      "Loader:4.89346170425415\n",
      "Inference:0.25312256813049316\n",
      "Val_Step:51\n",
      "Loader:4.720085144042969\n",
      "Inference:0.24840760231018066\n",
      "Val_Step:52\n",
      "Loader:4.845346927642822\n",
      "Inference:0.2520325183868408\n",
      "Val_Step:53\n",
      "Loader:4.769338846206665\n",
      "Inference:0.25130319595336914\n",
      "Val_Step:54\n",
      "Loader:5.012388229370117\n",
      "Inference:0.254288911819458\n",
      "Val_Step:55\n",
      "Loader:4.940046310424805\n",
      "Inference:0.26685667037963867\n",
      "Val_Step:56\n",
      "Loader:4.875258445739746\n",
      "Inference:0.27071714401245117\n",
      "Val_Step:57\n",
      "Loader:4.803098678588867\n",
      "Inference:0.25730347633361816\n",
      "Val_Step:58\n",
      "Loader:4.885841131210327\n",
      "Inference:0.2511918544769287\n",
      "Val_Step:59\n",
      "Loader:4.7352516651153564\n",
      "Inference:0.25024986267089844\n",
      "Val_Step:60\n",
      "Loader:4.953662633895874\n",
      "Inference:0.25119876861572266\n",
      "Val_Step:61\n",
      "Loader:4.754455089569092\n",
      "Inference:0.24836945533752441\n",
      "Val_Step:62\n",
      "Loader:4.9800331592559814\n",
      "Inference:0.25039076805114746\n",
      "Val_Step:63\n",
      "Loader:5.069706678390503\n",
      "Inference:0.2524728775024414\n",
      "Val_Step:64\n",
      "Loader:5.063502311706543\n",
      "Inference:0.26095151901245117\n",
      "Val_Step:65\n",
      "Loader:4.787299871444702\n",
      "Inference:3.257758378982544\n",
      "Val_Step:66\n",
      "Loader:4.734826326370239\n",
      "Inference:0.25736236572265625\n",
      "Val_Step:67\n",
      "Loader:4.647643327713013\n",
      "Inference:0.24980759620666504\n",
      "Val_Step:68\n",
      "Loader:4.937198877334595\n",
      "Inference:0.2552809715270996\n",
      "Val_Step:69\n",
      "Loader:4.816174268722534\n",
      "Inference:0.251537561416626\n",
      "Val_Step:70\n",
      "Loader:4.749949932098389\n",
      "Inference:0.2539699077606201\n",
      "Val_Step:71\n",
      "Loader:4.85937237739563\n",
      "Inference:0.25100159645080566\n",
      "Val_Step:72\n",
      "Loader:4.755914688110352\n",
      "Inference:0.25291943550109863\n",
      "Val_Step:73\n",
      "Loader:4.951105833053589\n",
      "Inference:0.2673635482788086\n",
      "Val_Step:74\n",
      "Loader:4.741214752197266\n",
      "Inference:0.26502037048339844\n",
      "Val_Step:75\n",
      "Loader:4.834964275360107\n",
      "Inference:0.2528495788574219\n",
      "Val_Step:76\n",
      "Loader:4.953019380569458\n",
      "Inference:0.2551555633544922\n",
      "Val_Step:77\n",
      "Loader:4.7771406173706055\n",
      "Inference:0.25188517570495605\n",
      "Val_Step:78\n",
      "Loader:4.96151328086853\n",
      "Inference:0.2530813217163086\n",
      "Val_Step:79\n",
      "Loader:4.83220911026001\n",
      "Inference:0.25339174270629883\n",
      "Val_Step:80\n",
      "Loader:4.937300443649292\n",
      "Inference:0.25437164306640625\n",
      "Val_Step:81\n",
      "Loader:4.7567057609558105\n",
      "Inference:0.25180673599243164\n",
      "Val_Step:82\n",
      "Loader:4.635197162628174\n",
      "Inference:0.2636117935180664\n",
      "Val_Step:83\n",
      "Loader:4.578578472137451\n",
      "Inference:0.25457239151000977\n",
      "Val_Step:84\n",
      "Loader:4.7326953411102295\n",
      "Inference:0.25124621391296387\n",
      "Val_Step:85\n",
      "Loader:4.798095226287842\n",
      "Inference:4.371718406677246\n",
      "Val_Step:86\n",
      "Loader:4.9735939502716064\n",
      "Inference:0.24997925758361816\n",
      "Val_Step:87\n",
      "Loader:4.926169157028198\n",
      "Inference:0.2501716613769531\n",
      "Val_Step:88\n",
      "Loader:4.8815813064575195\n",
      "Inference:0.25055456161499023\n",
      "Val_Step:89\n",
      "Loader:4.974169492721558\n",
      "Inference:0.24823403358459473\n",
      "Val_Step:90\n",
      "Loader:5.029166221618652\n",
      "Inference:0.25019001960754395\n",
      "Val_Step:91\n",
      "Loader:5.0032665729522705\n",
      "Inference:0.2693300247192383\n",
      "Val_Step:92\n",
      "Loader:5.061164855957031\n",
      "Inference:0.25709080696105957\n",
      "Val_Step:93\n",
      "Loader:5.393617391586304\n",
      "Inference:0.25043392181396484\n",
      "Val_Step:94\n",
      "Loader:4.852389335632324\n",
      "Inference:0.2503080368041992\n",
      "Val_Step:95\n",
      "Loader:4.94098424911499\n",
      "Inference:0.2515566349029541\n",
      "Val_Step:96\n",
      "Loader:4.9063098430633545\n",
      "Inference:0.2548224925994873\n",
      "Val_Step:97\n",
      "Loader:5.102030515670776\n",
      "Inference:0.25583529472351074\n",
      "Val_Step:98\n",
      "Loader:4.943690299987793\n",
      "Inference:0.2533833980560303\n",
      "Val_Step:99\n",
      "Loader:4.932171583175659\n",
      "Inference:0.2546515464782715\n",
      "Val_Step:100\n",
      "Loader:4.953677415847778\n",
      "Inference:0.27197861671447754\n",
      "Val_Step:101\n",
      "Loader:4.897467851638794\n",
      "Inference:0.2539682388305664\n",
      "Val_Step:102\n",
      "Loader:4.806059122085571\n",
      "Inference:0.2527439594268799\n",
      "Val_Step:103\n",
      "Loader:5.011388301849365\n",
      "Inference:5.124870300292969\n",
      "Val_Step:104\n",
      "Loader:5.005933523178101\n",
      "Inference:0.25300145149230957\n",
      "Val_Step:105\n",
      "Loader:4.923349142074585\n",
      "Inference:0.2483959197998047\n",
      "Val_Step:106\n",
      "Loader:5.010370969772339\n",
      "Inference:0.2544844150543213\n",
      "Val_Step:107\n",
      "Loader:5.018835544586182\n",
      "Inference:0.25107359886169434\n",
      "Val_Step:108\n",
      "Loader:4.980601072311401\n",
      "Inference:0.26317453384399414\n",
      "Val_Step:109\n",
      "Loader:5.35136342048645\n",
      "Inference:0.2515876293182373\n",
      "Val_Step:110\n",
      "Loader:4.879406213760376\n",
      "Inference:0.250347375869751\n",
      "Val_Step:111\n",
      "Loader:5.024135112762451\n",
      "Inference:0.25117015838623047\n",
      "Val_Step:112\n",
      "Loader:4.974667072296143\n",
      "Inference:0.2508871555328369\n",
      "Val_Step:113\n",
      "Loader:4.902655839920044\n",
      "Inference:0.2527797222137451\n",
      "Val_Step:114\n",
      "Loader:4.991174697875977\n",
      "Inference:0.2488865852355957\n",
      "Val_Step:115\n",
      "Loader:5.0171613693237305\n",
      "Inference:0.25117969512939453\n",
      "Val_Step:116\n",
      "Loader:5.103470802307129\n",
      "Inference:0.2518613338470459\n",
      "Val_Step:117\n",
      "Loader:5.4092698097229\n",
      "Inference:0.26221609115600586\n",
      "Val_Step:118\n",
      "Loader:5.2471818923950195\n",
      "Inference:0.2538471221923828\n",
      "Val_Step:119\n",
      "Loader:5.142885684967041\n",
      "Inference:0.251570463180542\n",
      "Val_Step:120\n",
      "Loader:5.270839214324951\n",
      "Inference:6.166086912155151\n",
      "Val_Step:121\n",
      "Loader:5.391485214233398\n",
      "Inference:0.2609748840332031\n",
      "Val_Step:122\n",
      "Loader:5.392921447753906\n",
      "Inference:0.2526512145996094\n",
      "Val_Step:123\n",
      "Loader:5.081179141998291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference:0.24918103218078613\n",
      "Val_Step:124\n",
      "Loader:5.088399887084961\n",
      "Inference:0.2693824768066406\n",
      "Val_Step:125\n",
      "Loader:5.097487449645996\n",
      "Inference:0.25815892219543457\n",
      "Val_Step:126\n",
      "Loader:5.1825761795043945\n",
      "Inference:0.25518012046813965\n",
      "Val_Step:127\n",
      "Loader:5.170257806777954\n",
      "Inference:0.2548253536224365\n",
      "Val_Step:128\n",
      "Loader:5.360436677932739\n",
      "Inference:0.2519054412841797\n",
      "Val_Step:129\n",
      "Loader:5.344872713088989\n",
      "Inference:0.24959635734558105\n",
      "Val_Step:130\n",
      "Loader:5.70245361328125\n",
      "Inference:0.25064992904663086\n",
      "Val_Step:131\n",
      "Loader:5.196382999420166\n",
      "Inference:0.2515723705291748\n",
      "Val_Step:132\n",
      "Loader:5.138046979904175\n",
      "Inference:0.25333404541015625\n",
      "Val_Step:133\n",
      "Loader:5.167848825454712\n",
      "Inference:0.26823902130126953\n",
      "Val_Step:134\n",
      "Loader:5.186892032623291\n",
      "Inference:0.24983525276184082\n",
      "Val_Step:135\n",
      "Loader:5.208659410476685\n",
      "Inference:0.25077271461486816\n",
      "Val_Step:136\n",
      "Loader:5.240781545639038\n",
      "Inference:0.2595536708831787\n",
      "Val_Step:137\n",
      "Loader:5.0702526569366455\n",
      "Inference:0.24988484382629395\n",
      "Val_Step:138\n",
      "Loader:5.447552442550659\n",
      "Inference:7.254865407943726\n",
      "Val_Step:139\n",
      "Loader:5.180498123168945\n",
      "Inference:0.25079822540283203\n",
      "Val_Step:140\n",
      "Loader:5.221029043197632\n",
      "Inference:0.26838207244873047\n",
      "Val_Step:141\n",
      "Loader:5.185484170913696\n",
      "Inference:0.25490498542785645\n",
      "Val_Step:142\n",
      "Loader:5.145959854125977\n",
      "Inference:0.2502937316894531\n",
      "Val_Step:143\n",
      "Loader:5.039475917816162\n",
      "Inference:0.25200748443603516\n",
      "Val_Step:144\n",
      "Loader:5.200480222702026\n",
      "Inference:0.2544386386871338\n",
      "Val_Step:145\n",
      "Loader:5.220773458480835\n",
      "Inference:0.24905776977539062\n",
      "Val_Step:146\n",
      "Loader:5.218719005584717\n",
      "Inference:0.2519688606262207\n",
      "Val_Step:147\n",
      "Loader:5.29135537147522\n",
      "Inference:0.25300121307373047\n",
      "Val_Step:148\n",
      "Loader:5.196931838989258\n",
      "Inference:0.2523305416107178\n",
      "Val_Step:149\n",
      "Loader:5.1375439167022705\n",
      "Inference:0.26894378662109375\n",
      "Val_Step:150\n",
      "Loader:5.287213563919067\n",
      "Inference:0.2546725273132324\n",
      "Val_Step:151\n",
      "Loader:5.229421377182007\n",
      "Inference:0.2541022300720215\n",
      "Val_Step:152\n",
      "Loader:5.1799962520599365\n",
      "Inference:0.27151918411254883\n",
      "Val_Step:153\n",
      "Loader:5.395143508911133\n",
      "Inference:0.26076173782348633\n",
      "Val_Step:154\n",
      "Loader:5.242160081863403\n",
      "Inference:0.24944639205932617\n",
      "Val_Step:155\n",
      "Loader:5.424044370651245\n",
      "Inference:8.06158185005188\n",
      "Val_Step:156\n",
      "Loader:4.8634607791900635\n",
      "Inference:0.2686903476715088\n",
      "Val_Step:157\n",
      "Loader:5.060385704040527\n",
      "Inference:0.2591996192932129\n",
      "Val_Step:158\n",
      "Loader:5.207225799560547\n",
      "Inference:0.25121235847473145\n",
      "Val_Step:159\n",
      "Loader:5.044151306152344\n",
      "Inference:0.2520434856414795\n",
      "Val_Step:160\n",
      "Loader:4.992215156555176\n",
      "Inference:0.25031423568725586\n",
      "Val_Step:161\n",
      "Loader:4.928821325302124\n",
      "Inference:0.24951457977294922\n",
      "Val_Step:162\n",
      "Loader:5.030916452407837\n",
      "Inference:0.2477583885192871\n",
      "Val_Step:163\n",
      "Loader:4.961404085159302\n",
      "Inference:0.2511873245239258\n",
      "Val_Step:164\n",
      "Loader:5.045210361480713\n",
      "Inference:0.254533052444458\n",
      "Val_Step:165\n",
      "Loader:5.299906969070435\n",
      "Inference:0.2675642967224121\n",
      "Val_Step:166\n",
      "Loader:5.183634281158447\n",
      "Inference:0.24990177154541016\n",
      "Val_Step:167\n",
      "Loader:5.215054035186768\n",
      "Inference:0.2549319267272949\n",
      "Val_Step:168\n",
      "Loader:5.1562180519104\n",
      "Inference:0.2532806396484375\n",
      "Val_Step:169\n",
      "Loader:5.444316864013672\n",
      "Inference:0.2522614002227783\n",
      "Val_Step:170\n",
      "Loader:5.1227240562438965\n",
      "Inference:0.25676417350769043\n",
      "Val_Step:171\n",
      "Loader:5.040195465087891\n",
      "Inference:8.639774560928345\n",
      "Val_Step:172\n",
      "Loader:5.229931831359863\n",
      "Inference:0.26973414421081543\n",
      "Val_Step:173\n",
      "Loader:5.215334415435791\n",
      "Inference:0.2531712055206299\n",
      "Val_Step:174\n",
      "Loader:5.419109582901001\n",
      "Inference:0.2514078617095947\n",
      "Val_Step:175\n",
      "Loader:5.114821672439575\n",
      "Inference:0.2512967586517334\n",
      "Val_Step:176\n",
      "Loader:5.064302921295166\n",
      "Inference:0.25548815727233887\n",
      "Val_Step:177\n",
      "Loader:5.319392204284668\n",
      "Inference:0.2502777576446533\n",
      "Val_Step:178\n",
      "Loader:5.156022548675537\n",
      "Inference:0.2534008026123047\n",
      "Val_Step:179\n",
      "Loader:5.0667335987091064\n",
      "Inference:0.2505967617034912\n",
      "Val_Step:180\n",
      "Loader:5.171226739883423\n",
      "Inference:0.25234055519104004\n",
      "Val_Step:181\n",
      "Loader:5.136448383331299\n",
      "Inference:0.26960062980651855\n",
      "Val_Step:182\n",
      "Loader:5.116464138031006\n",
      "Inference:0.2542428970336914\n",
      "Val_Step:183\n",
      "Loader:5.1509904861450195\n",
      "Inference:0.25147438049316406\n",
      "Val_Step:184\n",
      "Loader:5.2656025886535645\n",
      "Inference:0.2490990161895752\n",
      "Val_Step:185\n",
      "Loader:5.121119737625122\n",
      "Inference:0.263808012008667\n",
      "Val_Step:186\n",
      "Loader:5.085658311843872\n",
      "Inference:0.25025177001953125\n",
      "Val_Step:187\n",
      "Loader:5.21113657951355\n",
      "Inference:0.2572205066680908\n",
      "Val_Step:188\n",
      "Loader:5.207068920135498\n",
      "Inference:0.25333142280578613\n",
      "Val_Step:189\n",
      "Loader:5.033223628997803\n",
      "Inference:9.491798877716064\n",
      "Val_Step:190\n",
      "Loader:5.009588003158569\n",
      "Inference:0.2570796012878418\n",
      "Val_Step:191\n",
      "Loader:5.016002655029297\n",
      "Inference:0.2525906562805176\n",
      "Val_Step:192\n",
      "Loader:5.1286375522613525\n",
      "Inference:0.2510242462158203\n",
      "Val_Step:193\n",
      "Loader:5.073055267333984\n",
      "Inference:0.2559826374053955\n",
      "Val_Step:194\n",
      "Loader:5.102983236312866\n",
      "Inference:0.250821590423584\n",
      "Val_Step:195\n",
      "Loader:5.09692120552063\n",
      "Inference:0.2508091926574707\n",
      "Val_Step:196\n",
      "Loader:5.5084004402160645\n",
      "Inference:0.2733030319213867\n",
      "Val_Step:197\n",
      "Loader:5.497760534286499\n",
      "Inference:0.25856447219848633\n",
      "Val_Step:198\n",
      "Loader:5.165891408920288\n",
      "Inference:0.25409674644470215\n",
      "Val_Step:199\n",
      "Loader:5.199536085128784\n",
      "Inference:0.25121521949768066\n",
      "Val_Step:200\n",
      "Loader:5.1236042976379395\n",
      "Inference:0.25275635719299316\n",
      "Val_Step:201\n",
      "Loader:5.121402025222778\n",
      "Inference:0.2501075267791748\n",
      "Val_Step:202\n",
      "Loader:5.206101894378662\n",
      "Inference:0.25098657608032227\n",
      "Val_Step:203\n",
      "Loader:5.172602653503418\n",
      "Inference:0.2501366138458252\n",
      "Val_Step:204\n",
      "Loader:5.147212982177734\n",
      "Inference:0.25682544708251953\n",
      "Val_Step:205\n",
      "Loader:5.197056531906128\n",
      "Inference:0.2682185173034668\n",
      "Val_Step:206\n",
      "Loader:5.220228910446167\n",
      "Inference:10.348530292510986\n",
      "Val_Step:207\n",
      "Loader:4.990133285522461\n",
      "Inference:0.25150132179260254\n",
      "Val_Step:208\n",
      "Loader:5.128131866455078\n",
      "Inference:0.25368618965148926\n",
      "Val_Step:209\n",
      "Loader:5.011377811431885\n",
      "Inference:0.25297999382019043\n",
      "Val_Step:210\n",
      "Loader:5.0101048946380615\n",
      "Inference:0.2529768943786621\n",
      "Val_Step:211\n",
      "Loader:5.167268753051758\n",
      "Inference:0.24988341331481934\n",
      "Val_Step:212\n",
      "Loader:5.392421245574951\n",
      "Inference:0.2657933235168457\n",
      "Val_Step:213\n",
      "Loader:5.209885120391846\n",
      "Inference:0.25426483154296875\n",
      "Val_Step:214\n",
      "Loader:5.215474367141724\n",
      "Inference:0.25269389152526855\n",
      "Val_Step:215\n",
      "Loader:5.232623815536499\n",
      "Inference:0.252002477645874\n",
      "Val_Step:216\n",
      "Loader:5.20349645614624\n",
      "Inference:0.24796676635742188\n",
      "Val_Step:217\n",
      "Loader:5.2070581912994385\n",
      "Inference:0.2568206787109375\n",
      "Val_Step:218\n",
      "Loader:5.145212888717651\n",
      "Inference:0.2518734931945801\n",
      "Val_Step:219\n",
      "Loader:5.188056468963623\n",
      "Inference:0.2508735656738281\n",
      "Val_Step:220\n",
      "Loader:5.082575798034668\n",
      "Inference:0.25043511390686035\n",
      "Val_Step:221\n",
      "Loader:5.703639268875122\n",
      "Inference:0.2673766613006592\n",
      "Val_Step:222\n",
      "Loader:5.185225963592529\n",
      "Inference:0.25444698333740234\n",
      "Val_Step:223\n",
      "Loader:5.161577463150024\n",
      "Inference:11.704632759094238\n",
      "Val_Step:224\n",
      "Loader:5.3091607093811035\n",
      "Inference:0.25331544876098633\n",
      "Val_Step:225\n",
      "Loader:5.3110785484313965\n",
      "Inference:0.2521629333496094\n",
      "Val_Step:226\n",
      "Loader:5.0947394371032715\n",
      "Inference:0.25301361083984375\n",
      "Val_Step:227\n",
      "Loader:5.417824983596802\n",
      "Inference:0.2676050662994385\n",
      "Val_Step:228\n",
      "Loader:5.555012226104736\n",
      "Inference:0.252025842666626\n",
      "Val_Step:229\n",
      "Loader:5.205933094024658\n",
      "Inference:0.25342226028442383\n",
      "Val_Step:230\n",
      "Loader:5.305609464645386\n",
      "Inference:0.2512650489807129\n",
      "Val_Step:231\n",
      "Loader:5.265741586685181\n",
      "Inference:0.25037312507629395\n",
      "Val_Step:232\n",
      "Loader:5.223619222640991\n",
      "Inference:0.255878210067749\n",
      "Val_Step:233\n",
      "Loader:5.175800323486328\n",
      "Inference:0.25272154808044434\n",
      "Val_Step:234\n",
      "Loader:5.176925420761108\n",
      "Inference:0.24924015998840332\n",
      "Val_Step:235\n",
      "Loader:5.323925971984863\n",
      "Inference:0.2664787769317627\n",
      "Val_Step:236\n",
      "Loader:5.204535007476807\n",
      "Inference:0.2586398124694824\n",
      "Val_Step:237\n",
      "Loader:5.092443943023682\n",
      "Inference:0.2519981861114502\n",
      "Val_Step:238\n",
      "Loader:5.31789755821228\n",
      "Inference:0.2504384517669678\n",
      "Val_Step:239\n",
      "Loader:5.422472715377808\n",
      "Inference:0.252777099609375\n",
      "Val_Step:240\n",
      "Loader:5.239549875259399\n",
      "Inference:12.516340732574463\n",
      "Val_Step:241\n",
      "Loader:5.149432897567749\n",
      "Inference:0.25379347801208496\n",
      "Val_Step:242\n",
      "Loader:5.0361008644104\n",
      "Inference:0.2617790699005127\n",
      "Val_Step:243\n",
      "Loader:5.1993184089660645\n",
      "Inference:0.2514834403991699\n",
      "Val_Step:244\n",
      "Loader:5.243063688278198\n",
      "Inference:0.25377869606018066\n",
      "Val_Step:245\n",
      "Loader:5.10474967956543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference:0.2520151138305664\n",
      "Val_Step:246\n",
      "Loader:5.051320314407349\n",
      "Inference:0.26018548011779785\n",
      "Val_Step:247\n",
      "Loader:5.220085382461548\n",
      "Inference:0.2517220973968506\n",
      "Val_Step:248\n",
      "Loader:5.701671123504639\n",
      "Inference:0.2532482147216797\n",
      "Val_Step:249\n",
      "Loader:5.13836669921875\n",
      "Inference:0.25077080726623535\n",
      "Val_Step:250\n",
      "Loader:4.956829786300659\n",
      "Inference:0.2507350444793701\n",
      "Val_Step:251\n",
      "Loader:5.085843086242676\n",
      "Inference:0.26666712760925293\n",
      "Val_Step:252\n",
      "Loader:5.097516298294067\n",
      "Inference:0.25754523277282715\n",
      "Val_Step:253\n",
      "Loader:4.995311737060547\n",
      "Inference:0.2500636577606201\n",
      "Val_Step:254\n",
      "Loader:5.384106397628784\n",
      "Inference:0.2508726119995117\n",
      "Val_Step:255\n",
      "Loader:5.00697660446167\n",
      "Inference:0.24884676933288574\n",
      "Val_Step:256\n",
      "Loader:4.974262475967407\n",
      "Inference:0.2529337406158447\n",
      "Val_Step:257\n",
      "Loader:5.000724792480469\n",
      "Inference:0.2524595260620117\n",
      "Val_Step:258\n",
      "Loader:5.048516273498535\n",
      "Inference:13.546960830688477\n",
      "Val_Step:259\n",
      "Loader:5.120457887649536\n",
      "Inference:0.2587716579437256\n",
      "Val_Step:260\n",
      "Loader:5.069617748260498\n",
      "Inference:0.25222206115722656\n",
      "Val_Step:261\n",
      "Loader:5.074444532394409\n",
      "Inference:0.25236010551452637\n",
      "Val_Step:262\n",
      "Loader:5.11536979675293\n",
      "Inference:0.24982309341430664\n",
      "Val_Step:263\n",
      "Loader:6.006493330001831\n",
      "Inference:0.252896785736084\n",
      "Val_Step:264\n",
      "Loader:5.057379722595215\n",
      "Inference:0.2508225440979004\n",
      "Val_Step:265\n",
      "Loader:5.039606094360352\n",
      "Inference:0.2523369789123535\n",
      "Val_Step:266\n",
      "Loader:5.075958728790283\n",
      "Inference:0.2702929973602295\n",
      "Val_Step:267\n",
      "Loader:5.033940315246582\n",
      "Inference:0.25084733963012695\n",
      "Val_Step:268\n",
      "Loader:5.056250810623169\n",
      "Inference:0.2519204616546631\n",
      "Val_Step:269\n",
      "Loader:5.131884813308716\n",
      "Inference:0.2528848648071289\n",
      "Val_Step:270\n",
      "Loader:5.172843933105469\n",
      "Inference:0.25076985359191895\n",
      "Val_Step:271\n",
      "Loader:5.100476264953613\n",
      "Inference:0.2518160343170166\n",
      "Val_Step:272\n",
      "Loader:5.211221933364868\n",
      "Inference:0.2522921562194824\n",
      "Val_Step:273\n",
      "Loader:5.068848133087158\n",
      "Inference:0.25121426582336426\n",
      "Val_Step:274\n",
      "Loader:5.082145929336548\n",
      "Inference:0.2547187805175781\n",
      "Val_Step:275\n",
      "Loader:5.172100305557251\n",
      "Inference:13.26707911491394\n",
      "Val_Step:276\n",
      "Loader:5.0594048500061035\n",
      "Inference:0.2554347515106201\n",
      "Val_Step:277\n",
      "Loader:5.072017431259155\n",
      "Inference:0.2526552677154541\n",
      "Val_Step:278\n",
      "Loader:5.4329142570495605\n",
      "Inference:0.2519998550415039\n",
      "Val_Step:279\n",
      "Loader:5.8183674812316895\n",
      "Inference:0.2554457187652588\n",
      "Val_Step:280\n",
      "Loader:5.068036079406738\n",
      "Inference:0.25598597526550293\n",
      "Val_Step:281\n",
      "Loader:5.110613107681274\n",
      "Inference:0.2643272876739502\n",
      "Val_Step:282\n",
      "Loader:5.1622703075408936\n",
      "Inference:0.2637913227081299\n",
      "Val_Step:283\n",
      "Loader:5.096262216567993\n",
      "Inference:0.25692129135131836\n",
      "Val_Step:284\n",
      "Loader:5.070785999298096\n",
      "Inference:0.25686025619506836\n",
      "Val_Step:285\n",
      "Loader:5.042603969573975\n",
      "Inference:0.24983000755310059\n",
      "Val_Step:286\n",
      "Loader:5.039499282836914\n",
      "Inference:0.25243449211120605\n",
      "Val_Step:287\n",
      "Loader:5.07813286781311\n",
      "Inference:0.25182175636291504\n",
      "Val_Step:288\n",
      "Loader:5.00537633895874\n",
      "Inference:0.2563767433166504\n",
      "Val_Step:289\n",
      "Loader:4.965076923370361\n",
      "Inference:0.24833083152770996\n",
      "Val_Step:290\n",
      "Loader:5.006355047225952\n",
      "Inference:0.26466870307922363\n",
      "Val_Step:291\n",
      "Loader:5.168138027191162\n",
      "Inference:0.2616569995880127\n",
      "Val_Step:292\n",
      "Loader:5.14763069152832\n",
      "Inference:14.877686977386475\n",
      "Val_Step:293\n",
      "Loader:5.117438077926636\n",
      "Inference:0.2523491382598877\n",
      "Val_Step:294\n",
      "Loader:5.1468589305877686\n",
      "Inference:0.25090551376342773\n",
      "Val_Step:295\n",
      "Loader:5.2177534103393555\n",
      "Inference:0.25111889839172363\n",
      "Val_Step:296\n",
      "Loader:5.362466096878052\n",
      "Inference:0.2719533443450928\n",
      "Val_Step:297\n",
      "Loader:5.156779050827026\n",
      "Inference:0.2652769088745117\n",
      "Val_Step:298\n",
      "Loader:5.145319223403931\n",
      "Inference:0.2507510185241699\n",
      "Val_Step:299\n",
      "Loader:5.1239893436431885\n",
      "Inference:0.2507336139678955\n",
      "Val_Step:300\n",
      "Loader:5.1571056842803955\n",
      "Inference:0.251755952835083\n",
      "Val_Step:301\n",
      "Loader:5.150925159454346\n",
      "Inference:0.2511935234069824\n",
      "Val_Step:302\n",
      "Loader:5.180199384689331\n",
      "Inference:0.25438404083251953\n",
      "Val_Step:303\n",
      "Loader:5.176878929138184\n",
      "Inference:0.2500588893890381\n",
      "Val_Step:304\n",
      "Loader:5.09698224067688\n",
      "Inference:0.25873351097106934\n",
      "Val_Step:305\n",
      "Loader:5.345846891403198\n",
      "Inference:0.2673971652984619\n",
      "Val_Step:306\n",
      "Loader:5.189878940582275\n",
      "Inference:0.25188779830932617\n",
      "Val_Step:307\n",
      "Loader:5.358797788619995\n",
      "Inference:0.25049734115600586\n",
      "Val_Step:308\n",
      "Loader:5.046189785003662\n",
      "Inference:0.2503626346588135\n",
      "Val_Step:309\n",
      "Loader:5.162276744842529\n",
      "Inference:15.810854196548462\n",
      "Val_Step:310\n",
      "Loader:5.07061243057251\n",
      "Inference:0.25226664543151855\n",
      "Val_Step:311\n",
      "Loader:5.100033760070801\n",
      "Inference:0.2744021415710449\n",
      "Val_Step:312\n",
      "Loader:5.194563388824463\n",
      "Inference:0.25439453125\n",
      "Val_Step:313\n",
      "Loader:5.2640440464019775\n",
      "Inference:0.24967074394226074\n",
      "Val_Step:314\n",
      "Loader:5.805412292480469\n",
      "Inference:0.25716161727905273\n",
      "Val_Step:315\n",
      "Loader:5.133819103240967\n",
      "Inference:0.2502410411834717\n",
      "Val_Step:316\n",
      "Loader:5.026679992675781\n",
      "Inference:0.2524228096008301\n",
      "Val_Step:317\n",
      "Loader:5.181232213973999\n",
      "Inference:0.272197961807251\n",
      "Val_Step:318\n",
      "Loader:5.101097583770752\n",
      "Inference:0.2512044906616211\n",
      "Val_Step:319\n",
      "Loader:5.121844053268433\n",
      "Inference:0.24972224235534668\n",
      "Val_Step:320\n",
      "Loader:5.180570840835571\n",
      "Inference:0.2653019428253174\n",
      "Val_Step:321\n",
      "Loader:5.217148780822754\n",
      "Inference:0.2555224895477295\n",
      "Val_Step:322\n",
      "Loader:5.179465055465698\n",
      "Inference:0.25266504287719727\n",
      "Val_Step:323\n",
      "Loader:5.4946208000183105\n",
      "Inference:0.24957895278930664\n",
      "Val_Step:324\n",
      "Loader:5.29058313369751\n",
      "Inference:0.25739049911499023\n",
      "Val_Step:325\n",
      "Loader:5.237165927886963\n",
      "Inference:0.2520759105682373\n",
      "Val_Step:326\n",
      "Loader:5.324962377548218\n",
      "Inference:16.52905583381653\n",
      "Val_Step:327\n",
      "Loader:5.021406650543213\n",
      "Inference:0.2562718391418457\n",
      "Val_Step:328\n",
      "Loader:4.985736846923828\n",
      "Inference:0.2489461898803711\n",
      "Val_Step:329\n",
      "Loader:5.075869083404541\n",
      "Inference:0.24964427947998047\n",
      "Val_Step:330\n",
      "Loader:5.053053379058838\n",
      "Inference:0.25425219535827637\n",
      "Val_Step:331\n",
      "Loader:4.925927639007568\n",
      "Inference:0.24939179420471191\n",
      "Val_Step:332\n",
      "Loader:5.054357528686523\n",
      "Inference:0.2511775493621826\n",
      "Val_Step:333\n",
      "Loader:5.208879709243774\n",
      "Inference:0.2525289058685303\n",
      "Val_Step:334\n",
      "Loader:5.188387155532837\n",
      "Inference:0.27063941955566406\n",
      "Val_Step:335\n",
      "Loader:5.081445217132568\n",
      "Inference:0.2561304569244385\n",
      "Val_Step:336\n",
      "Loader:5.002677917480469\n",
      "Inference:0.25651097297668457\n",
      "Val_Step:337\n",
      "Loader:5.112848997116089\n",
      "Inference:0.2504267692565918\n",
      "Val_Step:338\n",
      "Loader:4.9564971923828125\n",
      "Inference:0.2715492248535156\n",
      "Val_Step:339\n",
      "Loader:5.014184474945068\n",
      "Inference:0.25118255615234375\n",
      "Val_Step:340\n",
      "Loader:5.058927059173584\n",
      "Inference:0.2506895065307617\n",
      "Val_Step:341\n",
      "Loader:5.117481470108032\n",
      "Inference:0.24964046478271484\n",
      "Val_Step:342\n",
      "Loader:5.106841087341309\n",
      "Inference:0.2496347427368164\n",
      "Val_Step:343\n",
      "Loader:5.072972774505615\n",
      "Inference:16.339678049087524\n",
      "Val_Step:344\n",
      "Loader:5.003864765167236\n",
      "Inference:0.251781702041626\n",
      "Val_Step:345\n",
      "Loader:5.103295564651489\n",
      "Inference:0.25271034240722656\n",
      "Val_Step:346\n",
      "Loader:5.081842660903931\n",
      "Inference:0.2496330738067627\n",
      "Val_Step:347\n",
      "Loader:5.024872064590454\n",
      "Inference:0.2474653720855713\n",
      "Val_Step:348\n",
      "Loader:5.074099540710449\n",
      "Inference:0.2518644332885742\n",
      "Val_Step:349\n",
      "Loader:5.035437107086182\n",
      "Inference:0.2664799690246582\n",
      "Val_Step:350\n",
      "Loader:5.106649875640869\n",
      "Inference:0.24870896339416504\n",
      "Val_Step:351\n",
      "Loader:5.12837290763855\n",
      "Inference:0.2529633045196533\n",
      "Val_Step:352\n",
      "Loader:5.072832345962524\n",
      "Inference:0.25098633766174316\n",
      "Val_Step:353\n",
      "Loader:5.8369810581207275\n",
      "Inference:0.25381016731262207\n",
      "Val_Step:354\n",
      "Loader:4.999778509140015\n",
      "Inference:0.2531921863555908\n",
      "Val_Step:355\n",
      "Loader:4.941503524780273\n",
      "Inference:0.24976730346679688\n",
      "Val_Step:356\n",
      "Loader:4.879064321517944\n",
      "Inference:0.25089263916015625\n",
      "Val_Step:357\n",
      "Loader:4.9290783405303955\n",
      "Inference:0.2496018409729004\n",
      "Val_Step:358\n",
      "Loader:5.243109703063965\n",
      "Inference:0.26740360260009766\n",
      "Val_Step:359\n",
      "Loader:4.965326547622681\n",
      "Inference:0.2522776126861572\n",
      "Val_Step:360\n",
      "Loader:4.94037127494812\n",
      "Inference:17.61207628250122\n",
      "Val_Step:361\n",
      "Loader:4.813086986541748\n",
      "Inference:0.2558619976043701\n",
      "Val_Step:362\n",
      "Loader:4.926377773284912\n",
      "Inference:0.2509498596191406\n",
      "Val_Step:363\n",
      "Loader:4.849719285964966\n",
      "Inference:0.25053882598876953\n",
      "Val_Step:364\n",
      "Loader:4.850917339324951\n",
      "Inference:0.2706897258758545\n",
      "Val_Step:365\n",
      "Loader:4.851604461669922\n",
      "Inference:0.25232601165771484\n",
      "Val_Step:366\n",
      "Loader:4.9802350997924805\n",
      "Inference:0.2517838478088379\n",
      "Val_Step:367\n",
      "Loader:4.878509759902954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference:0.2507014274597168\n",
      "Val_Step:368\n",
      "Loader:4.9191412925720215\n",
      "Inference:0.25563597679138184\n",
      "Val_Step:369\n",
      "Loader:4.892214775085449\n",
      "Inference:0.2526838779449463\n",
      "Val_Step:370\n",
      "Loader:4.837423801422119\n",
      "Inference:0.25170063972473145\n",
      "Val_Step:371\n",
      "Loader:4.839480876922607\n",
      "Inference:0.24966835975646973\n",
      "Val_Step:372\n",
      "Loader:4.884212017059326\n",
      "Inference:0.25185227394104004\n",
      "Val_Step:373\n",
      "Loader:4.905927658081055\n",
      "Inference:0.2664604187011719\n",
      "Val_Step:374\n",
      "Loader:5.225936651229858\n",
      "Inference:0.2506523132324219\n",
      "Val_Step:375\n",
      "Loader:5.084890127182007\n",
      "Inference:0.2537956237792969\n",
      "Val_Step:376\n",
      "Loader:5.096700668334961\n",
      "Inference:0.25197863578796387\n",
      "Val_Step:377\n",
      "Loader:4.905029296875\n",
      "Inference:18.01394510269165\n",
      "Val_Step:378\n",
      "Loader:4.856716156005859\n",
      "Inference:0.26459288597106934\n",
      "Val_Step:379\n",
      "Loader:4.906259536743164\n",
      "Inference:0.27141618728637695\n",
      "Val_Step:380\n",
      "Loader:4.882983922958374\n",
      "Inference:0.2571108341217041\n",
      "Val_Step:381\n",
      "Loader:4.878129720687866\n",
      "Inference:0.2508981227874756\n",
      "Val_Step:382\n",
      "Loader:4.874444961547852\n",
      "Inference:0.2512657642364502\n",
      "Val_Step:383\n",
      "Loader:4.828464031219482\n",
      "Inference:0.25139808654785156\n",
      "Val_Step:384\n",
      "Loader:4.836238622665405\n",
      "Inference:0.252887487411499\n",
      "Val_Step:385\n",
      "Loader:4.830789089202881\n",
      "Inference:0.24762272834777832\n",
      "Val_Step:386\n",
      "Loader:4.94633150100708\n",
      "Inference:0.25055980682373047\n",
      "Val_Step:387\n",
      "Loader:4.932884693145752\n",
      "Inference:0.26431703567504883\n",
      "Val_Step:388\n",
      "Loader:5.26725172996521\n",
      "Inference:0.26877760887145996\n",
      "Val_Step:389\n",
      "Loader:4.893840074539185\n",
      "Inference:0.25220394134521484\n",
      "Val_Step:390\n",
      "Loader:4.782777309417725\n",
      "Inference:0.2537674903869629\n",
      "Val_Step:391\n",
      "Loader:4.725958824157715\n",
      "Inference:0.25368475914001465\n",
      "Val_Step:392\n",
      "Loader:4.940795421600342\n",
      "Inference:0.2538430690765381\n",
      "Val_Step:393\n",
      "Loader:4.8382368087768555\n",
      "Inference:0.25136256217956543\n",
      "Val_Step:394\n",
      "Loader:4.906794548034668\n",
      "Inference:18.916529893875122\n",
      "Val_Step:395\n",
      "Loader:4.878061532974243\n",
      "Inference:0.25467371940612793\n",
      "Val_Step:396\n",
      "Loader:4.976921796798706\n",
      "Inference:0.2511720657348633\n",
      "Val_Step:397\n",
      "Loader:5.532404899597168\n",
      "Inference:0.25362348556518555\n",
      "Val_Step:398\n",
      "Loader:4.920055150985718\n",
      "Inference:0.2502431869506836\n",
      "Val_Step:399\n",
      "Loader:4.920352458953857\n",
      "Inference:0.2544863224029541\n",
      "Val_Step:400\n",
      "Loader:4.783770561218262\n",
      "Inference:0.2482438087463379\n",
      "Val_Step:401\n",
      "Loader:4.899831295013428\n",
      "Inference:0.24974870681762695\n",
      "Val_Step:402\n",
      "Loader:4.895708799362183\n",
      "Inference:0.26616954803466797\n",
      "Val_Step:403\n",
      "Loader:4.915479421615601\n",
      "Inference:0.2506906986236572\n",
      "Val_Step:404\n",
      "Loader:4.917717456817627\n",
      "Inference:0.25130653381347656\n",
      "Val_Step:405\n",
      "Loader:5.065106630325317\n",
      "Inference:0.2490096092224121\n",
      "Val_Step:406\n",
      "Loader:4.874056100845337\n",
      "Inference:0.25137758255004883\n",
      "Val_Step:407\n",
      "Loader:4.961588144302368\n",
      "Inference:0.2557978630065918\n",
      "Val_Step:408\n",
      "Loader:4.992932081222534\n",
      "Inference:0.25208020210266113\n",
      "Val_Step:409\n",
      "Loader:4.913020372390747\n",
      "Inference:0.2531898021697998\n",
      "Val_Step:410\n",
      "Loader:4.911471843719482\n",
      "Inference:0.2525651454925537\n",
      "Val_Step:411\n",
      "Loader:4.944287538528442\n",
      "Inference:19.61832022666931\n",
      "Val_Step:412\n",
      "Loader:4.842142581939697\n",
      "Inference:0.2536134719848633\n",
      "Val_Step:413\n",
      "Loader:4.883238315582275\n",
      "Inference:0.250934362411499\n",
      "Val_Step:414\n",
      "Loader:4.936343431472778\n",
      "Inference:0.2526977062225342\n",
      "Val_Step:415\n",
      "Loader:4.768032550811768\n",
      "Inference:0.25145626068115234\n",
      "Val_Step:416\n",
      "Loader:4.887111186981201\n",
      "Inference:0.27003908157348633\n",
      "Val_Step:417\n",
      "Loader:4.840472936630249\n",
      "Inference:0.2539958953857422\n",
      "Val_Step:418\n",
      "Loader:4.8942553997039795\n",
      "Inference:0.25893139839172363\n",
      "Val_Step:419\n",
      "Loader:4.851536512374878\n",
      "Inference:0.25220775604248047\n",
      "Val_Step:420\n",
      "Loader:4.933616399765015\n",
      "Inference:0.2506444454193115\n",
      "Val_Step:421\n",
      "Loader:4.810964107513428\n",
      "Inference:0.24784350395202637\n",
      "Val_Step:422\n",
      "Loader:4.89108943939209\n",
      "Inference:0.25222253799438477\n",
      "Val_Step:423\n",
      "Loader:5.096118688583374\n",
      "Inference:0.248626708984375\n",
      "Val_Step:424\n",
      "Loader:5.105473518371582\n",
      "Inference:0.2547602653503418\n",
      "Val_Step:425\n",
      "Loader:5.016815900802612\n",
      "Inference:0.27048468589782715\n",
      "Val_Step:426\n",
      "Loader:4.919404983520508\n",
      "Inference:0.25965428352355957\n",
      "Val_Step:427\n",
      "Loader:4.849977731704712\n",
      "Inference:0.2520589828491211\n",
      "Val_Step:428\n",
      "Loader:4.75862717628479\n",
      "Inference:20.558446407318115\n",
      "Val_Step:429\n",
      "Loader:4.777308225631714\n",
      "Inference:0.2508277893066406\n",
      "Val_Step:430\n",
      "Loader:4.815820693969727\n",
      "Inference:0.2710282802581787\n",
      "Val_Step:431\n",
      "Loader:4.907243728637695\n",
      "Inference:0.254133939743042\n",
      "Val_Step:432\n",
      "Loader:4.809008359909058\n",
      "Inference:0.2532808780670166\n",
      "Val_Step:433\n",
      "Loader:4.92557430267334\n",
      "Inference:0.25181031227111816\n",
      "Val_Step:434\n",
      "Loader:4.7754967212677\n",
      "Inference:0.251812219619751\n",
      "Val_Step:435\n",
      "Loader:4.933200120925903\n",
      "Inference:0.2525606155395508\n",
      "Val_Step:436\n",
      "Loader:4.680858850479126\n",
      "Inference:0.25028467178344727\n",
      "Val_Step:437\n",
      "Loader:4.743778705596924\n",
      "Inference:0.2623767852783203\n",
      "Val_Step:438\n",
      "Loader:4.8946311473846436\n",
      "Inference:0.25098347663879395\n",
      "Val_Step:439\n",
      "Loader:4.910608530044556\n",
      "Inference:0.26862168312072754\n",
      "Val_Step:440\n",
      "Loader:4.904382705688477\n",
      "Inference:0.2511613368988037\n",
      "Val_Step:441\n",
      "Loader:4.886670827865601\n",
      "Inference:0.25163865089416504\n",
      "Val_Step:442\n",
      "Loader:4.897209644317627\n",
      "Inference:0.268369197845459\n",
      "Val_Step:443\n",
      "Loader:4.8575475215911865\n",
      "Inference:0.25017595291137695\n",
      "Val_Step:444\n",
      "Loader:4.9170143604278564\n",
      "Inference:0.2513856887817383\n",
      "Val_Step:445\n",
      "Loader:4.934880018234253\n",
      "Inference:21.00413703918457\n",
      "Val_Step:446\n",
      "Loader:4.880397319793701\n",
      "Inference:0.25241613388061523\n",
      "Val_Step:447\n",
      "Loader:5.691643953323364\n",
      "Inference:0.25353050231933594\n",
      "Val_Step:448\n",
      "Loader:4.766569375991821\n",
      "Inference:0.2523820400238037\n",
      "Val_Step:449\n",
      "Loader:4.751912355422974\n",
      "Inference:0.25164318084716797\n",
      "Val_Step:450\n",
      "Loader:4.89114236831665\n",
      "Inference:0.2509591579437256\n",
      "Val_Step:451\n",
      "Loader:4.900595188140869\n",
      "Inference:0.2503995895385742\n",
      "Val_Step:452\n",
      "Loader:4.963850736618042\n",
      "Inference:0.2516143321990967\n",
      "Val_Step:453\n",
      "Loader:4.935255289077759\n",
      "Inference:0.26354241371154785\n",
      "Val_Step:454\n",
      "Loader:4.782779216766357\n",
      "Inference:0.25072526931762695\n",
      "Val_Step:455\n",
      "Loader:4.745190382003784\n",
      "Inference:0.26648640632629395\n",
      "Val_Step:456\n",
      "Loader:4.868561744689941\n",
      "Inference:0.2517681121826172\n",
      "Val_Step:457\n",
      "Loader:4.873468399047852\n",
      "Inference:0.24662256240844727\n",
      "Val_Step:458\n",
      "Loader:4.956335544586182\n",
      "Inference:0.25257301330566406\n",
      "Val_Step:459\n",
      "Loader:4.941678047180176\n",
      "Inference:0.2640819549560547\n",
      "Val_Step:460\n",
      "Loader:4.947564125061035\n",
      "Inference:0.24906134605407715\n",
      "Val_Step:461\n",
      "Loader:4.762624502182007\n",
      "Inference:0.2516815662384033\n",
      "Val_Step:462\n",
      "Loader:4.903926372528076\n",
      "Inference:21.9828839302063\n",
      "Val_Step:463\n",
      "Loader:4.835999011993408\n",
      "Inference:0.24724483489990234\n",
      "Val_Step:464\n",
      "Loader:4.890003204345703\n",
      "Inference:0.24895715713500977\n",
      "Val_Step:465\n",
      "Loader:4.9027063846588135\n",
      "Inference:0.2491152286529541\n",
      "Val_Step:466\n",
      "Loader:4.822259902954102\n",
      "Inference:0.25072360038757324\n",
      "Val_Step:467\n",
      "Loader:5.242703437805176\n",
      "Inference:0.2665529251098633\n",
      "Val_Step:468\n",
      "Loader:4.94377064704895\n",
      "Inference:0.2573373317718506\n",
      "Val_Step:469\n",
      "Loader:4.957470417022705\n",
      "Inference:0.25641298294067383\n",
      "Val_Step:470\n",
      "Loader:4.923571586608887\n",
      "Inference:0.25197839736938477\n",
      "Val_Step:471\n",
      "Loader:5.140528917312622\n",
      "Inference:0.25130605697631836\n",
      "Val_Step:472\n",
      "Loader:5.126629829406738\n",
      "Inference:0.25020289421081543\n",
      "Val_Step:473\n",
      "Loader:5.076014757156372\n",
      "Inference:0.25248217582702637\n",
      "Val_Step:474\n",
      "Loader:5.000473737716675\n",
      "Inference:0.2552518844604492\n",
      "Val_Step:475\n",
      "Loader:4.932128190994263\n",
      "Inference:0.25222039222717285\n",
      "Val_Step:476\n",
      "Loader:4.889160871505737\n",
      "Inference:0.26302599906921387\n",
      "Val_Step:477\n",
      "Loader:4.817080974578857\n",
      "Inference:0.25693535804748535\n",
      "Val_Step:478\n",
      "Loader:4.812509059906006\n",
      "Inference:0.2520418167114258\n",
      "Val_Step:479\n",
      "Loader:4.907727956771851\n",
      "Inference:23.02168583869934\n",
      "Val_Step:480\n",
      "Loader:4.82245659828186\n",
      "Inference:0.2506144046783447\n",
      "Val_Step:481\n",
      "Loader:4.8615288734436035\n",
      "Inference:0.26567721366882324\n",
      "Val_Step:482\n",
      "Loader:4.8933117389678955\n",
      "Inference:0.2531545162200928\n",
      "Val_Step:483\n",
      "Loader:4.928339719772339\n",
      "Inference:0.25142812728881836\n",
      "Val_Step:484\n",
      "Loader:4.768115520477295\n",
      "Inference:0.2526121139526367\n",
      "Val_Step:485\n",
      "Loader:4.917400360107422\n",
      "Inference:0.25200915336608887\n",
      "Val_Step:486\n",
      "Loader:4.827111005783081\n",
      "Inference:0.2520253658294678\n",
      "Val_Step:487\n",
      "Loader:4.903676986694336\n",
      "Inference:0.2512340545654297\n",
      "Val_Step:488\n",
      "Loader:4.751660108566284\n",
      "Inference:0.24817276000976562\n",
      "Val_Step:489\n",
      "Loader:4.733985662460327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference:0.24988722801208496\n",
      "Val_Step:490\n",
      "Loader:4.931384086608887\n",
      "Inference:0.2676708698272705\n",
      "Val_Step:491\n",
      "Loader:4.936732769012451\n",
      "Inference:0.2569265365600586\n",
      "Val_Step:492\n",
      "Loader:4.81702733039856\n",
      "Inference:0.2507779598236084\n",
      "Val_Step:493\n",
      "Loader:4.947946548461914\n",
      "Inference:0.25211143493652344\n",
      "Val_Step:494\n",
      "Loader:4.914796352386475\n",
      "Inference:0.2523982524871826\n",
      "Val_Step:495\n",
      "Loader:4.903579235076904\n",
      "Inference:0.2512972354888916\n",
      "Val_Step:496\n",
      "Loader:4.838625431060791\n",
      "Inference:23.75042986869812\n",
      "Val_Step:497\n",
      "Loader:4.893056631088257\n",
      "Inference:0.25409388542175293\n",
      "Val_Step:498\n",
      "Loader:4.656244993209839\n",
      "Inference:0.2520418167114258\n",
      "Val_Step:499\n",
      "Loader:4.85783576965332\n",
      "Inference:0.25234055519104004\n",
      "Val_Step:500\n",
      "Loader:4.891924858093262\n",
      "Inference:0.2506062984466553\n",
      "Val_Step:501\n",
      "Loader:4.901354074478149\n",
      "Inference:0.25101161003112793\n",
      "Val_Step:502\n",
      "Loader:4.67458701133728\n",
      "Inference:0.25429749488830566\n",
      "Val_Step:503\n",
      "Loader:5.818671464920044\n",
      "Inference:0.26688361167907715\n",
      "Val_Step:504\n",
      "Loader:4.935021638870239\n",
      "Inference:0.2499556541442871\n",
      "Val_Step:505\n",
      "Loader:4.828157186508179\n",
      "Inference:0.2506687641143799\n",
      "Val_Step:506\n",
      "Loader:4.898057699203491\n",
      "Inference:0.25115156173706055\n",
      "Val_Step:507\n",
      "Loader:4.733503103256226\n",
      "Inference:0.2509939670562744\n",
      "Val_Step:508\n",
      "Loader:4.688504695892334\n",
      "Inference:0.2512800693511963\n",
      "Val_Step:509\n",
      "Loader:4.896048069000244\n",
      "Inference:0.2535512447357178\n",
      "Val_Step:510\n",
      "Loader:4.837646722793579\n",
      "Inference:0.2530055046081543\n",
      "Val_Step:511\n",
      "Loader:4.964858293533325\n",
      "Inference:0.25543856620788574\n",
      "Val_Step:512\n",
      "Loader:4.597129583358765\n",
      "Inference:0.2701270580291748\n",
      "Val_Step:513\n",
      "Loader:4.843311309814453\n",
      "Inference:24.345120429992676\n",
      "Val_Step:514\n",
      "Loader:5.053554058074951\n",
      "Inference:0.24173617362976074\n",
      "Val_Step:515\n",
      "Loader:4.962286949157715\n",
      "Inference:0.25150609016418457\n",
      "Val_Step:516\n",
      "Loader:4.996428489685059\n",
      "Inference:0.252122163772583\n",
      "Val_Step:517\n",
      "Loader:5.109288692474365\n",
      "Inference:0.26636767387390137\n",
      "Val_Step:518\n",
      "Loader:5.024743556976318\n",
      "Inference:0.25049495697021484\n",
      "Val_Step:519\n",
      "Loader:5.1597771644592285\n",
      "Inference:0.25171995162963867\n",
      "Val_Step:520\n",
      "Loader:5.066772937774658\n",
      "Inference:0.2502748966217041\n",
      "Val_Step:521\n",
      "Loader:4.995952129364014\n",
      "Inference:0.2507617473602295\n",
      "Val_Step:522\n",
      "Loader:4.933043956756592\n",
      "Inference:0.25224757194519043\n",
      "Val_Step:523\n",
      "Loader:4.804604768753052\n",
      "Inference:0.2512805461883545\n",
      "Val_Step:524\n",
      "Loader:4.782100439071655\n",
      "Inference:0.2552461624145508\n",
      "Val_Step:525\n",
      "Loader:4.937368631362915\n",
      "Inference:0.2512242794036865\n",
      "Val_Step:526\n",
      "Loader:4.914507627487183\n",
      "Inference:0.2668452262878418\n",
      "Val_Step:527\n",
      "Loader:4.867940187454224\n",
      "Inference:0.2527775764465332\n",
      "Val_Step:528\n",
      "Loader:4.987858772277832\n",
      "Inference:0.2506883144378662\n",
      "Val_Step:529\n",
      "Loader:4.833433389663696\n",
      "Inference:0.2505528926849365\n",
      "Val_Step:530\n",
      "Loader:4.830338716506958\n",
      "Inference:25.44661569595337\n",
      "Val_Step:531\n",
      "Loader:4.742440462112427\n",
      "Inference:0.25667572021484375\n",
      "Val_Step:532\n",
      "Loader:4.908355712890625\n",
      "Inference:0.2527158260345459\n",
      "Val_Step:533\n",
      "Loader:5.042590856552124\n",
      "Inference:0.24959802627563477\n",
      "Val_Step:534\n",
      "Loader:4.980862617492676\n",
      "Inference:0.24916505813598633\n",
      "Val_Step:535\n",
      "Loader:4.7630205154418945\n",
      "Inference:0.25058674812316895\n",
      "Val_Step:536\n",
      "Loader:4.958535671234131\n",
      "Inference:0.2509024143218994\n",
      "Val_Step:537\n",
      "Loader:4.977855920791626\n",
      "Inference:0.25165772438049316\n",
      "Val_Step:538\n",
      "Loader:4.935565710067749\n",
      "Inference:0.25087809562683105\n",
      "Val_Step:539\n",
      "Loader:4.849752902984619\n",
      "Inference:0.26546621322631836\n",
      "Val_Step:540\n",
      "Loader:4.909079313278198\n",
      "Inference:0.25040149688720703\n",
      "Val_Step:541\n",
      "Loader:4.938046932220459\n",
      "Inference:0.2507016658782959\n",
      "Val_Step:542\n",
      "Loader:4.917290449142456\n",
      "Inference:0.2511129379272461\n",
      "Val_Step:543\n",
      "Loader:5.269675016403198\n",
      "Inference:0.2505466938018799\n",
      "Val_Step:544\n",
      "Loader:4.835763454437256\n",
      "Inference:0.2509028911590576\n",
      "Val_Step:545\n",
      "Loader:4.981928110122681\n",
      "Inference:0.2535386085510254\n",
      "Val_Step:546\n",
      "Loader:4.974950790405273\n",
      "Inference:0.24973559379577637\n",
      "Val_Step:547\n",
      "Loader:4.970016002655029\n",
      "Inference:26.474852561950684\n",
      "Val_Step:548\n",
      "Loader:4.804511308670044\n",
      "Inference:0.25662875175476074\n",
      "Val_Step:549\n",
      "Loader:4.690171480178833\n",
      "Inference:0.2507143020629883\n",
      "Val_Step:550\n",
      "Loader:4.9316017627716064\n",
      "Inference:0.24953317642211914\n",
      "Val_Step:551\n",
      "Loader:4.709722995758057\n",
      "Inference:0.2538933753967285\n",
      "Val_Step:552\n",
      "Loader:4.961129426956177\n",
      "Inference:0.2688727378845215\n",
      "Val_Step:553\n",
      "Loader:4.892213344573975\n",
      "Inference:0.2588534355163574\n",
      "Val_Step:554\n",
      "Loader:4.952974081039429\n",
      "Inference:0.2492363452911377\n",
      "Val_Step:555\n",
      "Loader:4.687068700790405\n",
      "Inference:0.24999499320983887\n",
      "Val_Step:556\n",
      "Loader:4.892786502838135\n",
      "Inference:0.2511937618255615\n",
      "Val_Step:557\n",
      "Loader:4.974402904510498\n",
      "Inference:0.2507588863372803\n",
      "Val_Step:558\n",
      "Loader:4.881664037704468\n",
      "Inference:0.2526264190673828\n",
      "Val_Step:559\n",
      "Loader:4.93475866317749\n",
      "Inference:0.25287604331970215\n",
      "Val_Step:560\n",
      "Loader:4.565877199172974\n",
      "Inference:0.25374293327331543\n",
      "Val_Step:561\n",
      "Loader:4.8404154777526855\n",
      "Inference:0.26850390434265137\n",
      "Val_Step:562\n",
      "Loader:4.957514524459839\n",
      "Inference:0.2539994716644287\n",
      "Val_Step:563\n",
      "Loader:4.853373050689697\n",
      "Inference:0.2508981227874756\n",
      "Val_Step:564\n",
      "Loader:4.974868059158325\n",
      "Inference:26.94719123840332\n",
      "Val_Step:565\n",
      "Loader:4.920091390609741\n",
      "Inference:0.26642942428588867\n",
      "Val_Step:566\n",
      "Loader:6.05646276473999\n",
      "Inference:0.24944448471069336\n",
      "Val_Step:567\n",
      "Loader:5.009052515029907\n",
      "Inference:0.2522106170654297\n",
      "Val_Step:568\n",
      "Loader:4.968749046325684\n",
      "Inference:0.251878023147583\n",
      "Val_Step:569\n",
      "Loader:4.9387829303741455\n",
      "Inference:0.2525968551635742\n",
      "Val_Step:570\n",
      "Loader:4.93956995010376\n",
      "Inference:0.25333642959594727\n",
      "Val_Step:571\n",
      "Loader:4.924242258071899\n",
      "Inference:0.24419403076171875\n",
      "Val_Step:572\n",
      "Loader:4.854530096054077\n",
      "Inference:0.2503178119659424\n",
      "Val_Step:573\n",
      "Loader:4.8269476890563965\n",
      "Inference:0.2556190490722656\n",
      "Val_Step:574\n",
      "Loader:4.51568078994751\n",
      "Inference:0.2679264545440674\n",
      "Val_Step:575\n",
      "Loader:4.809366703033447\n",
      "Inference:0.2537686824798584\n",
      "Val_Step:576\n",
      "Loader:4.706350803375244\n",
      "Inference:0.2537267208099365\n",
      "Val_Step:577\n",
      "Loader:5.0198845863342285\n",
      "Inference:0.24877500534057617\n",
      "Val_Step:578\n",
      "Loader:4.969020366668701\n",
      "Inference:0.2519681453704834\n",
      "Val_Step:579\n",
      "Loader:4.848986864089966\n",
      "Inference:0.2518787384033203\n",
      "Val_Step:580\n",
      "Loader:4.656618595123291\n",
      "Inference:0.252734899520874\n",
      "Val_Step:581\n",
      "Loader:4.827049493789673\n",
      "Inference:27.840334177017212\n",
      "Val_Step:582\n",
      "Loader:4.708198308944702\n",
      "Inference:0.2523972988128662\n",
      "Val_Step:583\n",
      "Loader:4.9385175704956055\n",
      "Inference:0.2504258155822754\n",
      "Val_Step:584\n",
      "Loader:4.790167331695557\n",
      "Inference:0.2503812313079834\n",
      "Val_Step:585\n",
      "Loader:4.945202589035034\n",
      "Inference:0.25029540061950684\n",
      "Val_Step:586\n",
      "Loader:4.90267539024353\n",
      "Inference:0.24845314025878906\n",
      "Val_Step:587\n",
      "Loader:4.957355499267578\n",
      "Inference:0.264986515045166\n",
      "Val_Step:588\n",
      "Loader:4.838449954986572\n",
      "Inference:0.24592161178588867\n",
      "Val_Step:589\n",
      "Loader:4.978313446044922\n",
      "Inference:0.26856279373168945\n",
      "Val_Step:590\n",
      "Loader:4.926353216171265\n",
      "Inference:0.25014710426330566\n",
      "Val_Step:591\n",
      "Loader:4.98049521446228\n",
      "Inference:0.2493305206298828\n",
      "Val_Step:592\n",
      "Loader:5.01179575920105\n",
      "Inference:0.25020527839660645\n",
      "Val_Step:593\n",
      "Loader:4.710773468017578\n",
      "Inference:0.2516787052154541\n",
      "Val_Step:594\n",
      "Loader:4.889235496520996\n",
      "Inference:0.24961376190185547\n",
      "Val_Step:595\n",
      "Loader:4.924129009246826\n",
      "Inference:0.2509756088256836\n",
      "Val_Step:596\n",
      "Loader:4.9027628898620605\n",
      "Inference:0.2700209617614746\n",
      "Val_Step:597\n",
      "Loader:4.878087043762207\n",
      "Inference:0.2540144920349121\n",
      "Val_Step:598\n",
      "Loader:4.899928331375122\n",
      "Inference:28.5107479095459\n",
      "Val_Step:599\n",
      "Loader:4.743896961212158\n",
      "Inference:0.25229430198669434\n",
      "Val_Step:600\n",
      "Loader:4.609056234359741\n",
      "Inference:0.26897764205932617\n",
      "Val_Step:601\n",
      "Loader:4.614073991775513\n",
      "Inference:0.2582895755767822\n",
      "Val_Step:602\n",
      "Loader:4.8948071002960205\n",
      "Inference:0.24885797500610352\n",
      "Val_Step:603\n",
      "Loader:4.901336908340454\n",
      "Inference:0.2516610622406006\n",
      "Val_Step:604\n",
      "Loader:4.857327222824097\n",
      "Inference:0.25444459915161133\n",
      "Val_Step:605\n",
      "Loader:4.753789663314819\n",
      "Inference:0.25293993949890137\n",
      "Val_Step:606\n",
      "Loader:4.814050197601318\n",
      "Inference:0.2511928081512451\n",
      "Val_Step:607\n",
      "Loader:4.842275619506836\n",
      "Inference:0.2503337860107422\n",
      "Val_Step:608\n",
      "Loader:4.90154242515564\n",
      "Inference:0.25246334075927734\n",
      "Val_Step:609\n",
      "Loader:4.8946216106414795\n",
      "Inference:0.27003955841064453\n",
      "Val_Step:610\n",
      "Loader:4.9012980461120605\n",
      "Inference:0.2581019401550293\n",
      "Val_Step:611\n",
      "Loader:4.626714468002319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference:0.26123952865600586\n",
      "Val_Step:612\n",
      "Loader:5.0500648021698\n",
      "Inference:0.2512784004211426\n",
      "Val_Step:613\n",
      "Loader:5.161428451538086\n",
      "Inference:0.24970221519470215\n",
      "Val_Step:614\n",
      "Loader:5.128931760787964\n",
      "Inference:0.2512683868408203\n",
      "Val_Step:615\n",
      "Loader:4.900631904602051\n",
      "Inference:29.40719723701477\n",
      "Val_Step:616\n",
      "Loader:4.845097780227661\n",
      "Inference:0.2555675506591797\n",
      "Val_Step:617\n",
      "Loader:4.718364477157593\n",
      "Inference:0.2503623962402344\n",
      "Val_Step:618\n",
      "Loader:4.847153663635254\n",
      "Inference:0.2524731159210205\n",
      "Val_Step:619\n",
      "Loader:5.109896183013916\n",
      "Inference:0.24843883514404297\n",
      "Val_Step:620\n",
      "Loader:4.902796030044556\n",
      "Inference:0.2514781951904297\n",
      "Val_Step:621\n",
      "Loader:4.860464334487915\n",
      "Inference:0.2689037322998047\n",
      "Val_Step:622\n",
      "Loader:4.849769830703735\n",
      "Inference:0.26706743240356445\n",
      "Val_Step:623\n",
      "Loader:4.83315372467041\n",
      "Inference:0.25158238410949707\n",
      "Val_Step:624\n",
      "Loader:4.652759075164795\n",
      "Inference:0.25423765182495117\n",
      "Val_Step:625\n",
      "Loader:4.807819604873657\n",
      "Inference:0.24798250198364258\n",
      "Val_Step:626\n",
      "Loader:5.011632204055786\n",
      "Inference:0.25043511390686035\n",
      "Val_Step:627\n",
      "Loader:4.8635923862457275\n",
      "Inference:0.24989008903503418\n",
      "Val_Step:628\n",
      "Loader:4.9220404624938965\n",
      "Inference:0.25530552864074707\n",
      "Val_Step:629\n",
      "Loader:4.930339813232422\n",
      "Inference:0.2546091079711914\n",
      "Val_Step:630\n",
      "Loader:4.907329797744751\n",
      "Inference:0.2691366672515869\n",
      "Val_Step:631\n",
      "Loader:4.510436058044434\n",
      "Inference:0.26871204376220703\n",
      "Val_Step:632\n",
      "Loader:4.928650617599487\n",
      "Inference:30.060782194137573\n",
      "Val_Step:633\n",
      "Loader:4.828805685043335\n",
      "Inference:0.2613036632537842\n",
      "Val_Step:634\n",
      "Loader:4.763440847396851\n",
      "Inference:0.26441502571105957\n",
      "Val_Step:635\n",
      "Loader:4.786224365234375\n",
      "Inference:0.2469797134399414\n",
      "Val_Step:636\n",
      "Loader:4.812714099884033\n",
      "Inference:0.2515113353729248\n",
      "Val_Step:637\n",
      "Loader:5.735321998596191\n",
      "Inference:0.2530076503753662\n",
      "Val_Step:638\n",
      "Loader:4.884158611297607\n",
      "Inference:0.251117467880249\n",
      "Val_Step:639\n",
      "Loader:4.885185718536377\n",
      "Inference:0.2554898262023926\n",
      "Val_Step:640\n",
      "Loader:4.7277679443359375\n",
      "Inference:0.25122523307800293\n",
      "Val_Step:641\n",
      "Loader:4.957903861999512\n",
      "Inference:0.2532663345336914\n",
      "Val_Step:642\n",
      "Loader:4.844579219818115\n",
      "Inference:0.2640047073364258\n",
      "Val_Step:643\n",
      "Loader:4.6849822998046875\n",
      "Inference:0.262864351272583\n",
      "Val_Step:644\n",
      "Loader:4.905871152877808\n",
      "Inference:0.2515294551849365\n",
      "Val_Step:645\n",
      "Loader:4.9158008098602295\n",
      "Inference:0.25208473205566406\n",
      "Val_Step:646\n",
      "Loader:4.691329002380371\n",
      "Inference:0.2516636848449707\n",
      "Val_Step:647\n",
      "Loader:4.634566068649292\n",
      "Inference:0.2540304660797119\n",
      "Val_Step:648\n",
      "Loader:4.529489994049072\n",
      "Inference:0.24646401405334473\n",
      "Val_Step:649\n",
      "Loader:4.92956018447876\n",
      "Inference:31.016035318374634\n",
      "Val_Step:650\n",
      "Loader:4.881121397018433\n",
      "Inference:0.25512123107910156\n",
      "Val_Step:651\n",
      "Loader:4.9054765701293945\n",
      "Inference:0.24811530113220215\n",
      "Val_Step:652\n",
      "Loader:4.923621416091919\n",
      "Inference:0.25170016288757324\n",
      "Val_Step:653\n",
      "Loader:4.900832414627075\n",
      "Inference:0.2477412223815918\n",
      "Val_Step:654\n",
      "Loader:4.925396919250488\n",
      "Inference:0.2646138668060303\n",
      "Val_Step:655\n",
      "Loader:5.090027809143066\n",
      "Inference:0.27076148986816406\n",
      "Val_Step:656\n",
      "Loader:5.019853115081787\n",
      "Inference:0.25711512565612793\n",
      "Val_Step:657\n",
      "Loader:5.0233681201934814\n",
      "Inference:0.2519497871398926\n",
      "Val_Step:658\n",
      "Loader:4.944792032241821\n",
      "Inference:0.25246143341064453\n",
      "Val_Step:659\n",
      "Loader:4.797734498977661\n",
      "Inference:0.2487492561340332\n",
      "Val_Step:660\n",
      "Loader:5.014697551727295\n",
      "Inference:0.25758814811706543\n",
      "Val_Step:661\n",
      "Loader:5.150129079818726\n",
      "Inference:0.25146055221557617\n",
      "Val_Step:662\n",
      "Loader:4.93800687789917\n",
      "Inference:0.2514021396636963\n",
      "Val_Step:663\n",
      "Loader:4.859382152557373\n",
      "Inference:0.26564788818359375\n",
      "Val_Step:664\n",
      "Loader:5.113264799118042\n",
      "Inference:0.26613378524780273\n",
      "Val_Step:665\n",
      "Loader:4.949987888336182\n",
      "Inference:0.2760305404663086\n",
      "Val_Step:666\n",
      "Loader:4.96588134765625\n",
      "Inference:32.41615557670593\n",
      "Val_Step:667\n",
      "Loader:4.974980115890503\n",
      "Inference:0.2681581974029541\n",
      "Val_Step:668\n",
      "Loader:4.82634973526001\n",
      "Inference:0.2557520866394043\n",
      "Val_Step:669\n",
      "Loader:5.23540186882019\n",
      "Inference:0.25332212448120117\n",
      "Val_Step:670\n",
      "Loader:5.002129554748535\n",
      "Inference:0.2528672218322754\n",
      "Val_Step:671\n",
      "Loader:4.9830687046051025\n",
      "Inference:0.2525310516357422\n",
      "Val_Step:672\n",
      "Loader:4.9229350090026855\n",
      "Inference:0.25052881240844727\n",
      "Val_Step:673\n",
      "Loader:5.077655553817749\n",
      "Inference:0.25105929374694824\n",
      "Val_Step:674\n",
      "Loader:5.055951833724976\n",
      "Inference:0.27034449577331543\n",
      "Val_Step:675\n",
      "Loader:5.098937273025513\n",
      "Inference:0.258131742477417\n",
      "Val_Step:676\n",
      "Loader:4.969635009765625\n",
      "Inference:0.2742910385131836\n",
      "Val_Step:677\n",
      "Loader:4.910393476486206\n",
      "Inference:0.2530488967895508\n",
      "Val_Step:678\n",
      "Loader:4.986046314239502\n",
      "Inference:0.25238537788391113\n",
      "Val_Step:679\n",
      "Loader:5.082282543182373\n",
      "Inference:0.2512333393096924\n",
      "Val_Step:680\n",
      "Loader:5.066450119018555\n",
      "Inference:0.2471628189086914\n",
      "Val_Step:681\n",
      "Loader:5.052950143814087\n",
      "Inference:0.25257301330566406\n",
      "Val_Step:682\n",
      "Loader:5.617455720901489\n",
      "Inference:0.2610664367675781\n",
      "Val_Step:683\n",
      "Loader:5.210547924041748\n",
      "Inference:39.07163977622986\n",
      "Val_Step:684\n",
      "Loader:5.117223501205444\n",
      "Inference:0.26880955696105957\n",
      "Val_Step:685\n",
      "Loader:5.106996774673462\n",
      "Inference:0.25569653511047363\n",
      "Val_Step:686\n",
      "Loader:5.260894060134888\n",
      "Inference:0.2650620937347412\n",
      "Val_Step:687\n",
      "Loader:5.255204200744629\n",
      "Inference:0.2537205219268799\n",
      "Val_Step:688\n",
      "Loader:5.169822454452515\n",
      "Inference:0.2500593662261963\n",
      "Val_Step:689\n",
      "Loader:5.431763410568237\n",
      "Inference:0.2569558620452881\n",
      "Val_Step:690\n",
      "Loader:5.066577196121216\n",
      "Inference:0.25288867950439453\n",
      "Val_Step:691\n",
      "Loader:5.247380971908569\n",
      "Inference:0.24805164337158203\n",
      "Val_Step:692\n",
      "Loader:5.18576192855835\n",
      "Inference:0.25202131271362305\n",
      "Val_Step:693\n",
      "Loader:5.145946979522705\n",
      "Inference:0.2583620548248291\n",
      "Val_Step:694\n",
      "Loader:5.239875316619873\n",
      "Inference:0.25099968910217285\n",
      "Val_Step:695\n",
      "Loader:5.1631104946136475\n",
      "Inference:0.2589900493621826\n",
      "Val_Step:696\n",
      "Loader:5.410579204559326\n",
      "Inference:0.25497961044311523\n",
      "Val_Step:697\n",
      "Loader:5.287605285644531\n",
      "Inference:0.25203704833984375\n",
      "Val_Step:698\n",
      "Loader:5.229995489120483\n",
      "Inference:0.25029635429382324\n",
      "Val_Step:699\n",
      "Loader:5.115703582763672\n",
      "Inference:0.2521083354949951\n",
      "Val_Step:700\n",
      "Loader:5.340290069580078\n",
      "Inference:42.7306444644928\n",
      "Val_Step:701\n",
      "Loader:5.102024078369141\n",
      "Inference:0.2560122013092041\n",
      "Val_Step:702\n",
      "Loader:5.105977773666382\n",
      "Inference:0.2607855796813965\n",
      "Val_Step:703\n",
      "Loader:5.211965322494507\n",
      "Inference:0.2534451484680176\n",
      "Val_Step:704\n",
      "Loader:5.261894941329956\n",
      "Inference:0.2716102600097656\n",
      "Val_Step:705\n",
      "Loader:5.1108386516571045\n",
      "Inference:0.25676846504211426\n",
      "Val_Step:706\n",
      "Loader:5.437800407409668\n",
      "Inference:0.25234103202819824\n",
      "Val_Step:707\n",
      "Loader:5.223229169845581\n",
      "Inference:0.25226545333862305\n",
      "Val_Step:708\n",
      "Loader:5.3914635181427\n",
      "Inference:0.25269627571105957\n",
      "Val_Step:709\n",
      "Loader:5.271740436553955\n",
      "Inference:0.25294065475463867\n",
      "Val_Step:710\n",
      "Loader:5.243943214416504\n",
      "Inference:0.25198841094970703\n",
      "Val_Step:711\n",
      "Loader:5.09933876991272\n",
      "Inference:0.26507568359375\n",
      "Val_Step:712\n",
      "Loader:4.998982906341553\n",
      "Inference:0.24839091300964355\n",
      "Val_Step:713\n",
      "Loader:5.247986555099487\n",
      "Inference:0.2676093578338623\n",
      "Val_Step:714\n",
      "Loader:5.0973286628723145\n",
      "Inference:0.25148773193359375\n",
      "Val_Step:715\n",
      "Loader:5.130653142929077\n",
      "Inference:0.24785876274108887\n",
      "Val_Step:716\n",
      "Loader:6.648105621337891\n",
      "Inference:0.25270533561706543\n",
      "Val_Step:717\n",
      "Loader:5.134743690490723\n",
      "Inference:41.538952112197876\n",
      "Val_Step:718\n",
      "Loader:4.959635257720947\n",
      "Inference:0.2569248676300049\n",
      "Val_Step:719\n",
      "Loader:5.07450008392334\n",
      "Inference:0.2519717216491699\n",
      "Val_Step:720\n",
      "Loader:5.2476770877838135\n",
      "Inference:0.252453088760376\n",
      "Val_Step:721\n",
      "Loader:5.1600282192230225\n",
      "Inference:0.2604868412017822\n",
      "Val_Step:722\n",
      "Loader:5.219786167144775\n",
      "Inference:0.2517368793487549\n",
      "Val_Step:723\n",
      "Loader:5.153621435165405\n",
      "Inference:0.2659273147583008\n",
      "Val_Step:724\n",
      "Loader:5.141657829284668\n",
      "Inference:0.25423765182495117\n",
      "Val_Step:725\n",
      "Loader:5.339760780334473\n",
      "Inference:0.2521519660949707\n",
      "Val_Step:726\n",
      "Loader:5.217701435089111\n",
      "Inference:0.25373053550720215\n",
      "Val_Step:727\n",
      "Loader:5.173811674118042\n",
      "Inference:0.25115275382995605\n",
      "Val_Step:728\n",
      "Loader:5.32881760597229\n",
      "Inference:0.24942660331726074\n",
      "Val_Step:729\n",
      "Loader:5.090622425079346\n",
      "Inference:0.2501339912414551\n",
      "Val_Step:730\n",
      "Loader:5.151700258255005\n",
      "Inference:0.2602858543395996\n",
      "Val_Step:731\n",
      "Loader:5.182260751724243\n",
      "Inference:0.25273633003234863\n",
      "Val_Step:732\n",
      "Loader:5.117583513259888\n",
      "Inference:0.27054524421691895\n",
      "Val_Step:733\n",
      "Loader:5.349872589111328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference:0.2572026252746582\n",
      "Val_Step:734\n",
      "Loader:5.168977499008179\n",
      "Inference:39.477030754089355\n",
      "Val_Step:735\n",
      "Loader:5.191528558731079\n",
      "Inference:0.2578737735748291\n",
      "Val_Step:736\n",
      "Loader:5.608321905136108\n",
      "Inference:0.25001001358032227\n",
      "Val_Step:737\n",
      "Loader:5.160480499267578\n",
      "Inference:0.25140976905822754\n",
      "Val_Step:738\n",
      "Loader:5.069202661514282\n",
      "Inference:0.2568984031677246\n",
      "Val_Step:739\n",
      "Loader:5.261093616485596\n",
      "Inference:0.2483656406402588\n",
      "Val_Step:740\n",
      "Loader:5.149172782897949\n",
      "Inference:0.26535654067993164\n",
      "Val_Step:741\n",
      "Loader:5.243167161941528\n",
      "Inference:0.25617027282714844\n",
      "Val_Step:742\n",
      "Loader:5.205844163894653\n",
      "Inference:0.28212714195251465\n",
      "Val_Step:743\n",
      "Loader:5.434542417526245\n",
      "Inference:0.25869321823120117\n",
      "Val_Step:744\n",
      "Loader:5.283932447433472\n",
      "Inference:0.24956226348876953\n",
      "Val_Step:745\n",
      "Loader:5.446509122848511\n",
      "Inference:0.2493584156036377\n",
      "Val_Step:746\n",
      "Loader:5.214984178543091\n",
      "Inference:0.25081849098205566\n",
      "Val_Step:747\n",
      "Loader:5.14432692527771\n",
      "Inference:0.24810409545898438\n",
      "Val_Step:748\n",
      "Loader:5.196723699569702\n",
      "Inference:0.2504289150238037\n",
      "Val_Step:749\n",
      "Loader:5.113427639007568\n",
      "Inference:0.26335620880126953\n",
      "Val_Step:750\n",
      "Loader:5.033975601196289\n",
      "Inference:0.25164151191711426\n",
      "Val_Step:751\n",
      "Loader:5.121510982513428\n",
      "Inference:46.22090172767639\n",
      "Val_Step:752\n",
      "Loader:5.144374370574951\n",
      "Inference:0.2594430446624756\n",
      "Val_Step:753\n",
      "Loader:5.237959146499634\n",
      "Inference:0.2489781379699707\n",
      "Val_Step:754\n",
      "Loader:5.232327938079834\n",
      "Inference:0.24988055229187012\n",
      "Val_Step:755\n",
      "Loader:5.310602903366089\n",
      "Inference:0.2510240077972412\n",
      "Val_Step:756\n",
      "Loader:5.149239540100098\n",
      "Inference:0.25127696990966797\n",
      "Val_Step:757\n",
      "Loader:5.311158895492554\n",
      "Inference:0.2514932155609131\n",
      "Val_Step:758\n",
      "Loader:5.629382848739624\n",
      "Inference:0.2575047016143799\n",
      "Val_Step:759\n",
      "Loader:5.214416980743408\n",
      "Inference:0.25151681900024414\n",
      "Val_Step:760\n",
      "Loader:5.139825820922852\n",
      "Inference:0.2514197826385498\n",
      "Val_Step:761\n",
      "Loader:5.238055944442749\n",
      "Inference:0.2623715400695801\n",
      "Val_Step:762\n",
      "Loader:5.257633686065674\n",
      "Inference:0.25072574615478516\n",
      "Val_Step:763\n",
      "Loader:5.251427412033081\n",
      "Inference:0.2645277976989746\n",
      "Val_Step:764\n",
      "Loader:5.127267599105835\n",
      "Inference:0.2558438777923584\n",
      "Val_Step:765\n",
      "Loader:5.228490114212036\n",
      "Inference:0.2522130012512207\n",
      "Val_Step:766\n",
      "Loader:5.1614556312561035\n",
      "Inference:0.24975800514221191\n",
      "Val_Step:767\n",
      "Loader:5.22238302230835\n",
      "Inference:0.26474928855895996\n",
      "Val_Step:768\n",
      "Loader:5.051165342330933\n",
      "Inference:46.74532461166382\n",
      "Val_Step:769\n",
      "Loader:5.3523619174957275\n",
      "Inference:0.26930665969848633\n",
      "Val_Step:770\n",
      "Loader:5.299961805343628\n",
      "Inference:0.26229047775268555\n",
      "Val_Step:771\n",
      "Loader:5.296625852584839\n",
      "Inference:0.25679850578308105\n",
      "Val_Step:772\n",
      "Loader:5.401779413223267\n",
      "Inference:0.24677467346191406\n",
      "Val_Step:773\n",
      "Loader:5.244025945663452\n",
      "Inference:0.2506415843963623\n",
      "Val_Step:774\n",
      "Loader:5.206550121307373\n",
      "Inference:0.2531619071960449\n",
      "Val_Step:775\n",
      "Loader:5.317809820175171\n",
      "Inference:0.2598762512207031\n",
      "Val_Step:776\n",
      "Loader:5.209732532501221\n",
      "Inference:0.25050902366638184\n",
      "Val_Step:777\n",
      "Loader:4.965885162353516\n",
      "Inference:0.2502477169036865\n",
      "Val_Step:778\n",
      "Loader:5.009167671203613\n",
      "Inference:0.16533446311950684\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# Train the model\n",
    "total_step = len(loader_valid)\n",
    "# Evaluate validation\n",
    "with torch.no_grad():\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    loss_valid = 0\n",
    "    icnt_val = 0\n",
    "    correct_class_val = torch.zeros(n_class)\n",
    "    correct_class_prob_val = torch.zeros(n_class)\n",
    "    total_class_val = torch.zeros(n_class)\n",
    "    result = {}\n",
    "    img = []\n",
    "    for ii in range(n_class):\n",
    "        result[ii] = []\n",
    "\n",
    "    model.eval()\n",
    "    t77 = time.time()\n",
    "    for ival, (images_val, _, path) in enumerate(loader_valid):\n",
    "        print(\"Val_Step:{}\".format(ival))\n",
    "        t7 = time.time()\n",
    "        print(\"Loader:{}\".format(t7-t77))\n",
    "        images_val = images_val.to(device)\n",
    "        outputs_val = model(images_val)\n",
    "        probs_val = torch.nn.Sigmoid()(outputs_val).cpu()\n",
    "\n",
    "        t8 = time.time()\n",
    "        t77 = t8\n",
    "        print(\"Inference:{}\".format(t8-t7))\n",
    "        \n",
    "        pred = probs_val.data\n",
    "\n",
    "        add_to_result(result, _, img, path, pred, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob = pd.DataFrame(result)\n",
    "df_img = pd.DataFrame({'image_id': img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7163</th>\n",
       "      <th>7164</th>\n",
       "      <th>7165</th>\n",
       "      <th>7166</th>\n",
       "      <th>7167</th>\n",
       "      <th>7168</th>\n",
       "      <th>7169</th>\n",
       "      <th>7170</th>\n",
       "      <th>7171</th>\n",
       "      <th>7172</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  7173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.000019  0.000019  0.000020  0.000019  0.000019  0.000019  0.000019   \n",
       "1  0.000018  0.000018  0.000019  0.000018  0.000018  0.000019  0.000018   \n",
       "2  0.000014  0.000014  0.000014  0.000014  0.000014  0.000014  0.000014   \n",
       "3  0.000013  0.000013  0.000013  0.000013  0.000013  0.000013  0.000013   \n",
       "4  0.000038  0.000038  0.000039  0.000038  0.000038  0.000039  0.000038   \n",
       "\n",
       "       7         8         9       ...         7163      7164      7165  \\\n",
       "0  0.000019  0.000019  0.000019    ...     0.000019  0.000021  0.000019   \n",
       "1  0.000018  0.000018  0.000019    ...     0.000018  0.000023  0.000018   \n",
       "2  0.000014  0.000014  0.000015    ...     0.000014  0.000019  0.000014   \n",
       "3  0.000013  0.000013  0.000013    ...     0.000013  0.000015  0.000013   \n",
       "4  0.000038  0.000038  0.000040    ...     0.000038  0.000049  0.000038   \n",
       "\n",
       "       7166      7167      7168      7169      7170      7171      7172  \n",
       "0  0.000019  0.000019  0.000020  0.000019  0.000019  0.000019  0.000020  \n",
       "1  0.000019  0.000018  0.000020  0.000018  0.000018  0.000018  0.000019  \n",
       "2  0.000014  0.000014  0.000016  0.000014  0.000014  0.000014  0.000014  \n",
       "3  0.000013  0.000013  0.000014  0.000013  0.000013  0.000013  0.000013  \n",
       "4  0.000039  0.000038  0.000042  0.000038  0.000038  0.000039  0.000041  \n",
       "\n",
       "[5 rows x 7173 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6e4c794d707761744877453d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44683973366a3546784d773d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45526a6d51764c4e4633383d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66563932463636774a786b3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4845534e6a546a76704f383d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   image_id\n",
       "0  6e4c794d707761744877453d\n",
       "1  44683973366a3546784d773d\n",
       "2  45526a6d51764c4e4633383d\n",
       "3  66563932463636774a786b3d\n",
       "4  4845534e6a546a76704f383d"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_img.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_prob.join(other=df_img, how='left').set_index(keys='image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('stage_1_probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7163</th>\n",
       "      <th>7164</th>\n",
       "      <th>7165</th>\n",
       "      <th>7166</th>\n",
       "      <th>7167</th>\n",
       "      <th>7168</th>\n",
       "      <th>7169</th>\n",
       "      <th>7170</th>\n",
       "      <th>7171</th>\n",
       "      <th>7172</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6e4c794d707761744877453d</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44683973366a3546784d773d</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45526a6d51764c4e4633383d</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66563932463636774a786b3d</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845534e6a546a76704f383d</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  7173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0         1         2         3         4     \\\n",
       "image_id                                                                     \n",
       "6e4c794d707761744877453d  0.000019  0.000019  0.000020  0.000019  0.000019   \n",
       "44683973366a3546784d773d  0.000018  0.000018  0.000019  0.000018  0.000018   \n",
       "45526a6d51764c4e4633383d  0.000014  0.000014  0.000014  0.000014  0.000014   \n",
       "66563932463636774a786b3d  0.000013  0.000013  0.000013  0.000013  0.000013   \n",
       "4845534e6a546a76704f383d  0.000038  0.000038  0.000039  0.000038  0.000038   \n",
       "\n",
       "                              5         6         7         8         9     \\\n",
       "image_id                                                                     \n",
       "6e4c794d707761744877453d  0.000019  0.000019  0.000019  0.000019  0.000019   \n",
       "44683973366a3546784d773d  0.000019  0.000018  0.000018  0.000018  0.000019   \n",
       "45526a6d51764c4e4633383d  0.000014  0.000014  0.000014  0.000014  0.000015   \n",
       "66563932463636774a786b3d  0.000013  0.000013  0.000013  0.000013  0.000013   \n",
       "4845534e6a546a76704f383d  0.000039  0.000038  0.000038  0.000038  0.000040   \n",
       "\n",
       "                            ...         7163      7164      7165      7166  \\\n",
       "image_id                    ...                                              \n",
       "6e4c794d707761744877453d    ...     0.000019  0.000021  0.000019  0.000019   \n",
       "44683973366a3546784d773d    ...     0.000018  0.000023  0.000018  0.000019   \n",
       "45526a6d51764c4e4633383d    ...     0.000014  0.000019  0.000014  0.000014   \n",
       "66563932463636774a786b3d    ...     0.000013  0.000015  0.000013  0.000013   \n",
       "4845534e6a546a76704f383d    ...     0.000038  0.000049  0.000038  0.000039   \n",
       "\n",
       "                              7167      7168      7169      7170      7171  \\\n",
       "image_id                                                                     \n",
       "6e4c794d707761744877453d  0.000019  0.000020  0.000019  0.000019  0.000019   \n",
       "44683973366a3546784d773d  0.000018  0.000020  0.000018  0.000018  0.000018   \n",
       "45526a6d51764c4e4633383d  0.000014  0.000016  0.000014  0.000014  0.000014   \n",
       "66563932463636774a786b3d  0.000013  0.000014  0.000013  0.000013  0.000013   \n",
       "4845534e6a546a76704f383d  0.000038  0.000042  0.000038  0.000038  0.000039   \n",
       "\n",
       "                              7172  \n",
       "image_id                            \n",
       "6e4c794d707761744877453d  0.000020  \n",
       "44683973366a3546784d773d  0.000019  \n",
       "45526a6d51764c4e4633383d  0.000014  \n",
       "66563932463636774a786b3d  0.000013  \n",
       "4845534e6a546a76704f383d  0.000041  \n",
       "\n",
       "[5 rows x 7173 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bool = df>=0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_bool.sum()!=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('input/stage_2_sample_submission.csv')\n",
    "sub.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2b2b2f64445950756265493d</th>\n",
       "      <td>/m/0sgh53y /m/0g4cd0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2b2b30717675476653584d3d</th>\n",
       "      <td>/m/0sgh53y /m/0g4cd0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2b2b362f6b57704e4b31773d</th>\n",
       "      <td>/m/0sgh53y /m/0g4cd0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2b2b3950504f34493336733d</th>\n",
       "      <td>/m/0sgh53y /m/0g4cd0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2b2b43386a5769574d50513d</th>\n",
       "      <td>/m/0sgh53y /m/0g4cd0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        labels\n",
       "image_id                                      \n",
       "2b2b2f64445950756265493d  /m/0sgh53y /m/0g4cd0\n",
       "2b2b30717675476653584d3d  /m/0sgh53y /m/0g4cd0\n",
       "2b2b362f6b57704e4b31773d  /m/0sgh53y /m/0g4cd0\n",
       "2b2b3950504f34493336733d  /m/0sgh53y /m/0g4cd0\n",
       "2b2b43386a5769574d50513d  /m/0sgh53y /m/0g4cd0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_bool.shape[0]):\n",
    "    tmp_labels = ' '.join([imgset_valid.idx_to_class[j] for j in np.where(df_bool.iloc[i,:])[0] ])\n",
    "    sub.loc[df_bool.index[i], 'labels'] = tmp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2b2b2f64445950756265493d</th>\n",
       "      <td>/m/019sc6 /m/01cd9 /m/01g317 /m/02cwm /m/02rfd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2b2b30717675476653584d3d</th>\n",
       "      <td>/m/01g317 /m/01lcwm /m/01prls /m/021mp2 /m/07y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2b2b362f6b57704e4b31773d</th>\n",
       "      <td>/m/019sc6 /m/01cd9 /m/01g317 /m/01kr8f /m/02cs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2b2b3950504f34493336733d</th>\n",
       "      <td>/m/01g317 /m/01ykh /m/0270h /m/02q08p0 /m/02wb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2b2b43386a5769574d50513d</th>\n",
       "      <td>/m/015p6 /m/01g317 /m/02cqfm /m/03rbf6 /m/03vt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     labels\n",
       "image_id                                                                   \n",
       "2b2b2f64445950756265493d  /m/019sc6 /m/01cd9 /m/01g317 /m/02cwm /m/02rfd...\n",
       "2b2b30717675476653584d3d  /m/01g317 /m/01lcwm /m/01prls /m/021mp2 /m/07y...\n",
       "2b2b362f6b57704e4b31773d  /m/019sc6 /m/01cd9 /m/01g317 /m/01kr8f /m/02cs...\n",
       "2b2b3950504f34493336733d  /m/01g317 /m/01ykh /m/0270h /m/02q08p0 /m/02wb...\n",
       "2b2b43386a5769574d50513d  /m/015p6 /m/01g317 /m/02cqfm /m/03rbf6 /m/03vt..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgset_valid.class_to_desc['/m/05s2s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label='/m/01g317 /m/09j2d /m/0dzct /m/07j7r /m/05s2s /m/07yv9'\n",
    "# for i in range(sub.shape[0]):\n",
    "#     sub.iloc[i, 0] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sub.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
